{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import datetime\n",
    "import glob\n",
    "import stanza\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kezidict = set([\n",
    "'Fekete-Győr András',\n",
    "'Borbélyné Bárdi Zsuzsanna',\n",
    "'Hajnal Miklós',\n",
    "'Körömi Attila',\n",
    "'Mándi László',\n",
    "'Orosz Anna',\n",
    "'Tóth Endre',\n",
    "'Cseh Katalin',\n",
    "'Donáth Anna Júlia',\n",
    "'Soproni Tamás',\n",
    "'Déri Tibor',\n",
    "'Orosz Anna',\n",
    "'Nyirati Klára',\n",
    "'Pikó András',\n",
    "'Balogh Csaba',\n",
    "'Kerpel-Fronius Gábor',\n",
    "'Momentum',\n",
    "'momentum',\n",
    "'Fekete-Győr'\n",
    "'Fekete Győr',\n",
    "'Donáth Anna'\n",
    "'Donáth',\n",
    "'Nyirati',\n",
    "'Pikó',\n",
    "'Kerpel-Fronius',\n",
    "'Mándi',\n",
    "'Körömi',\n",
    "'Kádár Barnabás',\n",
    "'Hadházy',\n",
    "'Hadházy Ákos'\n",
    "'Szél Bernadett',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_searchlist = [[each] for each in list(kezidict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onlywithneighbours(ofthislist):\n",
    "    try:\n",
    "        filtered = [each for each in ofthislist \n",
    "                    if each+1 in ofthislist or each-1 in ofthislist]\n",
    "    except TypeError:\n",
    "        filtered = [each for each in ofthislist \n",
    "                    if str(int(each)+1) in ofthislist or str(int(each)-1) in ofthislist]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_numerical_sequences(inlist):\n",
    "\n",
    "    inlist=sorted(inlist)\n",
    "\n",
    "    breakindeces=[i for i,j in enumerate(inlist)\n",
    "                    if (j+1 not in inlist and j in inlist)]\n",
    "\n",
    "    sublists=[]\n",
    "    for index, each in enumerate(breakindeces):\n",
    "        if index==0:\n",
    "            sublists.append([x for x in inlist\n",
    "                               if x<=inlist[each]])\n",
    "        if index!=0:\n",
    "            sublists.append([x for x in inlist\n",
    "                               if x<=inlist[each] and x>inlist[breakindeces[index-1]]])\n",
    "\n",
    "    return sublists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validalias(alias):\n",
    "    return True\n",
    "   # if len(str(alias).strip()) > 5 and len(str(alias).strip().split(' ')) > 1: return True\n",
    "   # else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchfinder(text,searchforthese):\n",
    "    matches=[alias\n",
    "             for persondata_searchtarget in searchforthese\n",
    "             for alias in persondata_searchtarget\n",
    "             if validalias(alias) and alias.lower() in str(text).lower()]\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillextracols(whichdictionary, whichrowtofill, withthislist, unlessitslongerthanthis):\n",
    "    if not len(withthislist) > unlessitslongerthanthis and len(withthislist)>0:\n",
    "        for i, e in enumerate(withthislist):\n",
    "            targetdf.loc[whichrowtofill,whichdictionary+str(i)]=e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_extra_columns(num_of_columns_for_each_dict):\n",
    "    for each in num_of_columns_for_each_dict:\n",
    "        for index in range(num_of_columns_for_each_dict[each]):\n",
    "            targetdf[each + str(index)]=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dictionary_class:\n",
    "    def __init__(self, name, maxcolnum, searchlist=None, geo=False):\n",
    "        self.name = name\n",
    "        self.maxcolnum = maxcolnum\n",
    "        self.searchlist = searchlist\n",
    "        self.geo = geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries=[\n",
    "dictionary_class('momentumdict',\n",
    "           10,\n",
    "           momentum_searchlist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_sorted_by_date_after_a_date(look_for_this_pattern,cutoffdate):\n",
    "    \n",
    "    csvs = glob.glob(look_for_this_pattern)\n",
    "    datetimes=[datetime.datetime(int(each.split('/')[-1][5:9]),\n",
    "                             int(each.split('/')[-1][10:12]),\n",
    "                             int(each.split('/')[-1][13:15]),\n",
    "                             int(each.split('/')[-1][16:18]),\n",
    "                             int(each.split('/')[-1][19:21]),\n",
    "                             int(each.split('/')[-1][22:24])) for each in csvs]\n",
    "\n",
    "    dt_csvs_filtered=[[dt, csv] for dt, csv in zip(datetimes,csvs) if dt > datetime.datetime(*cutoffdate)]\n",
    "    \n",
    "    sorted_filtered_csvs = [csv\n",
    "                        for _, csv in sorted(\n",
    "                                         zip([eachpair[0] for eachpair in dt_csvs_filtered],\n",
    "                                             [eachpair[1] for eachpair in dt_csvs_filtered]))]\n",
    "    \n",
    "    return sorted_filtered_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugmode = False\n",
    "\n",
    "preMomFile = 'live_updated3_dict_onlymomentum_'\n",
    "postMomFileSzokereso = '_szokereso_result.csv'\n",
    "postMomFileSzurt = '_dfUnifiedNanFilteredOnlySomeColsUpdated3.csv'\n",
    "postMomFileErrorlog = '_ERRORLOG.txt'\n",
    "\n",
    "inputPathAndWildcard = '/mnt/volume/anagy/mediascraper/mediaScraper/output/data*csv'\n",
    "szokeresoResFilesPath =   '/mnt/volume/jupyter/szokereso/cron/szokeresores/'\n",
    "szokeresoResFilesPathAndWildcard = szokeresoResFilesPath + preMomFile + '*' + postMomFileSzokereso\n",
    "momentumraSzurtSzokeresesPath    = szokeresoResFilesPath + 'momentumraszurt/'\n",
    "\n",
    "\n",
    "listOfColsWeWantToOutput = ['DOC_ID','TITLE','SCRAPETIME','TEXT','momentumdict0', 'momentumdict1',\n",
    "                            'momentumdict2', 'momentumdict3', 'momentumdict4', 'momentumdict5',\n",
    "                            'momentumdict6', 'momentumdict7', 'momentumdict8', 'momentumdict9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputFiles(pathAndWildcard=szokeresoResFilesPathAndWildcard):\n",
    "    outputFiles = glob.glob(pathAndWildcard)\n",
    "    return outputFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTodoFilesWithoutOutput(todoFiles,outputFiles=getOutputFiles()):\n",
    "    return [todoFile for todoFile in todoFiles\n",
    "           if not any([todoFile.split('/')[-1].split('.')[0] in szokeresoOutput for szokeresoOutput in getOutputFiles()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doThisWhenNoFileIsFoundToProcess(sleepThisMuch=5*60):\n",
    "    print('No more files found to process. Sleeping '+str(sleepThisMuch)+' seconds.')\n",
    "    time.sleep(sleepThisMuch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "\n",
    "    todoFiles=get_files_sorted_by_date_after_a_date(inputPathAndWildcard,[2020,7,1,0])\n",
    "    todoFilesWithoutOutput = getTodoFilesWithoutOutput(todoFiles)\n",
    "    \n",
    "    if len(todoFilesWithoutOutput) == 0:\n",
    "        doThisWhenNoFileIsFoundToProcess()\n",
    "        continue\n",
    "        \n",
    "    print('processing: '+todoFilesWithoutOutput[0])    \n",
    "\n",
    "    targetcsv=todoFilesWithoutOutput[0]\n",
    "    try:\n",
    "        targetdf = pd.read_csv(targetcsv)\n",
    "        prepare_extra_columns({dictionary.name: dictionary.maxcolnum for dictionary in dictionaries})\n",
    "        for idictionary, dictionary in enumerate(dictionaries):\n",
    "            for icell, cell in enumerate(list(targetdf['TEXT'])):\n",
    "                if type(cell) is not float:\n",
    "                    if dictionary.searchlist is not None:\n",
    "                        fillextracols(dictionary.name,icell,matchfinder(cell,dictionary.searchlist),dictionary.maxcolnum)\n",
    "                    if dictionary.searchlist is None:\n",
    "                        fillextracols(dictionary.name,icell,stanzanamesearch(cell),dictionary.maxcolnum)\n",
    "        \n",
    "        filenamecore = targetcsv.split('/')[-1].split('.')[0]\n",
    "        szokeresoResFilePathAndName=szokeresoResFilesPath+preMomFile+filenamecore+postMomFileSzokereso\n",
    "        \n",
    "        if not debugmode: targetdf.to_csv(szokeresoResFilePathAndName)\n",
    "\n",
    "        df = pd.read_csv(szokeresoResFilePathAndName)\n",
    "        df = df[~df['momentumdict0'].isna()]\n",
    "        df[listOfColsWeWantToOutput].to_csv(momentumraSzurtSzokeresesPath+preMomFile+filenamecore+postMomFileSzurt)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:\n",
    "        the_type, the_value, the_traceback = sys.exc_info()\n",
    "        outlist = [the_type, the_value, targetcsv, dictionary.name, icell]\n",
    "        if not debugmode:\n",
    "            with open(szokeresoResFilePathAndName+postMomFileErrorlog, 'w') as f:\n",
    "                for item in outlist:\n",
    "                    f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
