{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from collections import ChainMap\n",
    "import os\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def didMoreThanThisManySecondsElapsedSinceEndOfThatDay(singleDate,seconds):\n",
    "    '''\n",
    "    datetime.datetime.now() returns an object like this:\n",
    "        datetime.datetime(2020, 8, 17, 9, 26, 21, 78730)\n",
    "\n",
    "    '''\n",
    "\n",
    "    return (datetime.datetime.now() - (singleDate + datetime.timedelta(days=1))).total_seconds() > seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSearchListFromTabName(tabName,pathToExcelFile=excelFile):\n",
    "    '''\n",
    "    Example usage: getSearchListFromTabName('LMP') returns:\n",
    "\n",
    "    [['LMP', 'Lehet Más A Politika'],\n",
    "     ['Csárdi Antal', 'Csárdi'],\n",
    "     ['Demeter Márta', 'Demeter'],\n",
    "     ['Ungár Péter', 'Ungár']]\n",
    "\n",
    "    The excel file on the LMP tab looks like this, compare:\n",
    "    https://raw.githubusercontent.com/zabop/szokeresoDocs/master/howTheSzotarLooksLike.png\n",
    "\n",
    "    pd.ExcelFile() reads in the whole excel file, with all tabs.\n",
    "\n",
    "    dfs is a dict created with a dict comprehension.\n",
    "    Keys are tab names of the excel file.\n",
    "    Values are the list of lists, one shown above. \n",
    "\n",
    "    xl.parse(sheetname.header=None) returns a dataframe.\n",
    "    If not all rows have equal number of columns, nans will appear.\n",
    "    For example: xl.parse('MSZP',header=None).values.tolist() returns:\n",
    "\n",
    "    [['MSZP', 'Magyar Szocialista Párt', nan, 'Szocik'],\n",
    "     ['Ujhelyi István', 'Ujhelyi', nan, nan],\n",
    "     ['Kunhalmi Ágnes', 'Kunhalmi', nan, nan],\n",
    "     ['Hiller István', 'Hiller', nan, nan],\n",
    "     ['Molnár Gyula', nan, nan, nan],\n",
    "     ['Bangóné Borbély Ildikó', 'Bangóné', nan, nan],\n",
    "     ['Mesterházy Attila', 'Mesterházy', nan, nan],\n",
    "     ['Tóth Bertalan', nan, nan, nan],\n",
    "     ['Tóth Csaba', nan, nan, nan],\n",
    "     ['Tüttő Kata', 'Tüttő', nan, nan]]\n",
    "\n",
    "    The MSZP tab looks like this in the original excel file:\n",
    "    https://raw.githubusercontent.com/zabop/szokeresoDocs/master/tabMSZP.PNG\n",
    "    We can see that C1 is unreasonably left blank, but so the first line includes a nan in the third place.\n",
    "    There are other nans too, which we wouldn't want to return.\n",
    "\n",
    "    for person in xl.parse(sheetname,header=None).values.tolist() is looping through each list.\n",
    "    Ie first item:\n",
    "    ['MSZP', 'Magyar Szocialista Párt', nan, 'Szocik']\n",
    "    second item:\n",
    "    ['Ujhelyi István', 'Ujhelyi', nan, nan].\n",
    "\n",
    "    [alias for alias in person if type(alias) is not float] is looping through these lists.\n",
    "    Ie first item:\n",
    "    MSZP\n",
    "    second item:\n",
    "    'Magyar Szocialista Párt'\n",
    "    third item:\n",
    "    nan.\n",
    "\n",
    "    The result of this inner list comprehension is a list not containing nans, by the filtering them out: if not float.\n",
    "\n",
    "    dfs will contain this for every tab of the excel file. We only return one value of the dfs dict.\n",
    "\n",
    "    getSearchListFromTabName('MSZP') will return:\n",
    "    [['MSZP', 'Magyar Szocialista Párt', 'Szocik'],\n",
    "     ['Ujhelyi István', 'Ujhelyi'],\n",
    "     ['Kunhalmi Ágnes', 'Kunhalmi'],\n",
    "     ['Hiller István', 'Hiller'],\n",
    "     ['Molnár Gyula'],\n",
    "     ['Bangóné Borbély Ildikó', 'Bangóné'],\n",
    "     ['Mesterházy Attila', 'Mesterházy'],\n",
    "     ['Tóth Bertalan'],\n",
    "     ['Tóth Csaba'],\n",
    "     ['Tüttő Kata', 'Tüttő']]\n",
    "\n",
    "    We are doing more calculation than strictly needed.\n",
    "    We are returning only one value from a dict, but creating the whole dict.\n",
    "    This isn't a performance-limiting issue though, as this operation is performed once per tab.\n",
    "    The potential runtime gain by doing this better is in the order of, so we don't care.\n",
    "\n",
    "    (If bothered, try tabName == sheetname at the end of dict comprehension, but haven't tested this.)\n",
    "\n",
    "    The commented out line after DONT DO THIS includes a .dropna(), which is not behaving as would be desired here.\n",
    "    It drops every row with a nan, the entire row, not just the nans from it.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    pathToExcelFile=excelFile\n",
    "    xl = pd.ExcelFile(pathToExcelFile)\n",
    "    #dfs = {sheetname: xl.parse(sheetname, header=None).dropna().values.tolist() for sheetname in xl.sheet_names}\n",
    "    dfs = {sheetname: [[alias for alias in person if type(alias) is not float]\n",
    "                              for person in xl.parse(sheetname,header=None).values.tolist()]\n",
    "                              for sheetname in xl.sheet_names}\n",
    "    return dfs[tabName]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validalias(alias):\n",
    "    '''\n",
    "    The lines commented out were used at an earlier stage of the project.\n",
    "    Some dictionaries contained aliases which we didn't want to use.\n",
    "\n",
    "    (By dictionaries I mean list of entities, each entity having different names, ie 'MSZP', 'Magyar Szocialista Párt', 'Szocik'.\n",
    "    The different aliases in this case is 'MSZP', 'Magyar Szocialista Párt', 'Szocik', entity is: 'MSZP')\n",
    "\n",
    "    We filetered them with conditions:\n",
    "\n",
    "    - it had to be longer than 5 characters without trailing and leading spaces\n",
    "    - it had to be at least a bigram, ie at least one space between first and last non-space character\n",
    "\n",
    "    Ilénke wouldn't have been a valid alias, Nagy Ilén would've been.\n",
    "\n",
    "    Left here if needed in future, now everything is taken as a valid alias (that's why return True).\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    return True\n",
    "   # if len(str(alias).strip()) > 5 and len(str(alias).strip().split(' ')) > 1: return True\n",
    "   # else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchfinder(text,searchforthese):\n",
    "    '''\n",
    "    This function uses list comprehensions on nested lists.\n",
    "    A good visualization on how that works: https://i.stack.imgur.com/0GoV5.gif\n",
    "    From here: https://stackoverflow.com/a/45079294/8565438. I recommend to understand this answer.\n",
    "\n",
    "    We iterate through searchforthese, which is a list of alias lists, ie:\n",
    "\n",
    "    [['LMP', 'Lehet Más A Politika'],\n",
    "     ['Csárdi Antal', 'Csárdi'],\n",
    "     ['Demeter Márta', 'Demeter'],\n",
    "     ['Ungár Péter', 'Ungár']]\n",
    "\n",
    "    persondata_searchtarget is the individual alias lists, (ie ['LMP', 'Lehet Más A Politika'], then ['Csárdi Antal', 'Csárdi']).\n",
    "    We iterate through these (ie take LMP, then Lehet Más A Politika) & check for conditions.\n",
    "\n",
    "    If these conditions are fulfilled, the alias which fulfilled those conditions will be part of mathces.\n",
    "\n",
    "    These contitions:\n",
    "    The alias should be a valid alias (ie validalias(alias) should be True)\n",
    "    alias.lower() in str(text).lower() should be True.\n",
    "\n",
    "    'ElEfÁnT'.lower() is elefánt: lowercasing both alias & text is used to avoid inconsistencies in capitalization.\n",
    "    str(np.nan) is 'nan'. It is used in case input data contains nans, which potentially screws up the function.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    matchfinder('LMP, legyen meleg Péter, Csárdi Antal nem csárdi', [['LMP', 'Lehet Más A Politika'],\n",
    "                                                                     ['Csárdi Antal', 'Csárdi'],\n",
    "                                                                     ['Demeter Márta', 'Demeter'],\n",
    "                                                                     ['Ungár Péter', 'Ungár']])\n",
    "\n",
    "    Returns: ['LMP', 'Csárdi Antal', 'Csárdi'].\n",
    "\n",
    "    We see that occasionally we detect a false positive: here, be returning csárdi.\n",
    "    If we don't lowercase everything, we'll have false negatives.\n",
    "    Make your choices.\n",
    "    '''    \n",
    "    matches=[alias\n",
    "             for persondata_searchtarget in searchforthese\n",
    "             for alias in persondata_searchtarget\n",
    "             if validalias(alias) and alias.lower() in str(text).lower()]\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dictionary_class:\n",
    "    '''\n",
    "    Each dictionary has a name, maxcolnum, searchlist, geo attributes.\n",
    "    \n",
    "    name: the name of the dictionary\n",
    "    \n",
    "    maxcolnum: the maximum number of different entries we want to find in a text\n",
    "    If we find more, we will say we haven't found any of them.\n",
    "    (This is to tackle texts which were signed by a lot of people but is not about those people.)\n",
    "    searchlist is the list of alias lists, ie:\n",
    "    \n",
    "     [['LMP', 'Lehet Más A Politika'],\n",
    "      ['Csárdi Antal', 'Csárdi'],\n",
    "      ['Demeter Márta', 'Demeter'],\n",
    "      ['Ungár Péter', 'Ungár']]\n",
    "    \n",
    "    geo is a boolean, refering to a dictionary containing geographical names.\n",
    "    They are treated differently to people's names sometimes.\n",
    "    \n",
    "    '''    \n",
    "    def __init__(self, name, maxcolnum, searchlist=None, geo=False):\n",
    "        self.name = name\n",
    "        self.maxcolnum = maxcolnum\n",
    "        self.searchlist = searchlist\n",
    "        self.geo = geo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_sorted_by_date_after_a_date(look_for_this_pattern, cutoffdate):\n",
    "    '''\n",
    "    look_for_this_pattern should be a wildcard, ie: '/mnt/volume/anagy/mediascraper/mediaScraper/output/data*csv'\n",
    "    cutoffdate should be a list in the format of [year, month, day, 0], ie: [2020,7,1,0]\n",
    "    \n",
    "    csvs will be a list of files like this, with the example look_for_this_pattern wildcard above:\n",
    "    \n",
    "    ['/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-08-17_16:01:34.csv',\n",
    "     '/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-27_06:00:42.csv',\n",
    "     '/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-26_22:00:58.csv',\n",
    "     ...]\n",
    "     \n",
    "    These are the scraped input files.\n",
    "    They are generated every two hours.\n",
    "    data_2020-07-26_22:00:58.csv was generated (roughly) at 2020 July 22th 22h, & it took 00:58 to produce the file.\n",
    "     \n",
    "    re.findall(r'\\d+', each) finds all the digits in the variable each.\n",
    "    Source: https://stackoverflow.com/a/4289348/8565438\n",
    "\n",
    "    Examples:\n",
    "    \n",
    "    re.findall(r'\\d+', 'A 3 kismalac és az 1 farkas meséjének 10edik változata')\n",
    "    returns:\n",
    "    ['3', '1', '10']\n",
    "    \n",
    "    re.findall(r'\\d+', '/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-08-17_16:01:34.csv')\n",
    "    returns:\n",
    "    ['2020', '08', '17', '16', '01', '34']\n",
    "    \n",
    "    \n",
    "    |   !!!WARNING!!!:\n",
    "    |   DO NOT USE NUMERAL CHARACTERS IN PATH LEADING TO INPUT FILES.\n",
    "    |   For example:\n",
    "    |   re.findall(r'\\d+', '/mnt/volume/anagy/mediascraper/mediaScraper/output2/data_2020-08-17_16:01:34.csv')\n",
    "    |   returns:\n",
    "    |   ['2', '2020', '08', '17', '16', '01', '34']\n",
    "    |   The '2' in the front is clearly not what we want.\n",
    "    \n",
    "    \n",
    "    The inner list comprehension converts these to ints.\n",
    "    The first 4 element of this list is what we care about, so we include the [:4].\n",
    "    \n",
    "    datetimes will be a list of datetime.datetime objects, for example, one element of the list can be:\n",
    "    datetime.datetime(2020, 8, 17, 16, 0)\n",
    "    The * used in creation of datetimes list is to unpack argument lists, as described in this answer, for example:\n",
    "    https://stackoverflow.com/a/36908/8565438\n",
    "    \n",
    "    dt_csvs_filtered will be a list of lists.\n",
    "    These lists will contain a datetime.datetime object & the csv file it was created from.\n",
    "    dt_csvs_filtered will only contain those lists which had a datetime.datetime object in them satisfying a condition.\n",
    "    Condition: datetime.datetime object within list must reference a later point in time than datetime.datetime(*cutoffdate).\n",
    "    \n",
    "    sorted_filtered_csvs is the csv filenames from the dt_csvs_filtered list.\n",
    "    They are sorted by chronologically using the datetime.datetime objects within dt_csvs_filtered.\n",
    "    More detailed description here: https://stackoverflow.com/a/6618543/8565438\n",
    "    '''\n",
    "    csvs = glob.glob(look_for_this_pattern)\n",
    "    datetimes=[datetime.datetime(*[int(num) for num in re.findall(r'\\d+', each)[:4]]) for each in csvs]\n",
    "    dt_csvs_filtered=[[dt, csv] for dt, csv in zip(datetimes,csvs) if dt >= datetime.datetime(*cutoffdate)]\n",
    "    sorted_filtered_csvs = [csv\n",
    "                        for _, csv in sorted(\n",
    "                                         zip([eachpair[0] for eachpair in dt_csvs_filtered],\n",
    "                                             [eachpair[1] for eachpair in dt_csvs_filtered]))]\n",
    "    return sorted_filtered_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathFinder(clientName,path=str(pathlib.Path().absolute())):\n",
    "    '''\n",
    "    This function is to return strings used in paths, filenames, wildcards.\n",
    "    \n",
    "    str(pathlib.Path().absolute()) returns the directory which the code is run from, without final /.\n",
    "    Ie str(pathlib.Path().absolute()):\n",
    "    '/mnt/volume/jupyter/szokereso/negyedikfeladatUjraNegy'\n",
    "    In the same Jupyter Notebook, !pwd is:\n",
    "    /mnt/volume/jupyter/szokereso/negyedikfeladatUjraNegy\n",
    "    ''' \n",
    "    preMomFile = 'live_'\n",
    "    postMomFileSzokereso = '_szokereso_result.csv'\n",
    "    postMomFileSzurt = '_szurt.csv'\n",
    "    postMomFileErrorlog = '_ERRORLOG.txt'\n",
    "\n",
    "    inputPathAndWildcard = '/mnt/volume/anagy/mediascraper/mediaScraper/output/data*csv'\n",
    "    szokeresoResFilesPath =   path+'/'+clientName+'/szokeresores/'\n",
    "    momentumraSzurtSzokeresesPath    = szokeresoResFilesPath + 'clientreszurt/'\n",
    "    szokeresoResFilesPathAndWildcard = momentumraSzurtSzokeresesPath + preMomFile + '*' + postMomFileSzurt\n",
    "\n",
    "    return preMomFile,postMomFileSzokereso,inputPathAndWildcard,postMomFileSzurt,szokeresoResFilesPath,szokeresoResFilesPathAndWildcard,momentumraSzurtSzokeresesPath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputFiles(pathAndWildcard):\n",
    "    '''\n",
    "    Returning files the script outputted.\n",
    "    '''    \n",
    "    outputFiles = glob.glob(pathAndWildcard)\n",
    "    return outputFiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTodoFilesWithoutOutput(todoFiles,outputFiles):\n",
    "    '''\n",
    "    todoFiles is a list of files which we want to have performed operations on.\n",
    "    outputFiles is a list of files resulting from these operations.\n",
    "    \n",
    "    Example usage:\n",
    "    \n",
    "    getTodoFilesWithoutOutput(todoFiles=['/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_00:00:24.csv',\n",
    "                                     '/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_02:00:18.csv',\n",
    "                                     '/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_04:00:22.csv'],\n",
    "                              outputFiles=['live_data_2020-07-01_00:00:24_szurt.csv'])\n",
    "                              \n",
    "    todoFiles is looped through, & upon fulfilling a condition, each todoFile is put back to the list:\n",
    "    [todoFile for todoFile in todoFiles if condition]\n",
    "    The condition is:\n",
    "    not any([todoFile.split('/')[-1].split('.')[0] in szokeresoOutput for szokeresoOutput in outputFiles])\n",
    "    \n",
    "    If todoFile is: '/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_00:00:24.csv'\n",
    "    todoFile.split('/')[-1].split('.')[0] is: 'data_2020-07-01_00:00:24'\n",
    "    \n",
    "    todoFile.split('/')[-1].split('.')[0] in szokeresoOutput is a boolean.\n",
    "    If szokeresoOutput is 'live_data_2020-07-01_00:00:24_szurt.csv'.\n",
    "    \n",
    "    Example:\n",
    "    'data_2020-07-01_00:00:24' in szokeresoOutput\n",
    "    is evaluated to be True.\n",
    "    \n",
    "    'data_2020-07-01_04:00:22' in szokeresoOutput\n",
    "    is ecaluated to be False.\n",
    "    \n",
    "    By looping through all the outputfiles, we produce a list of booleans:\n",
    "    [todoFile.split('/')[-1].split('.')[0] in szokeresoOutput for szokeresoOutput in outputFiles]\n",
    "    The nth element of this list is True if the nth element of outputFiles is the output corresponding to input file todoFile.\n",
    "    \n",
    "    WARNING: be cautious when renaming outputfiles, not to screw up the functionality of this function.\n",
    "    \n",
    "    If any element of this list if True, there is an output for corresponding to todoFile.\n",
    "    Therefore, we want to return todoFile only if not any of the elements of this list is True:\n",
    "    if not any([todoFile.split('/')[-1].split('.')[0] in szokeresoOutput for szokeresoOutput in outputFiles])]\n",
    "    \n",
    "    for any(), see: https://docs.python.org/3/library/functions.html#any\n",
    "    '''    \n",
    "    return [todoFile for todoFile in todoFiles\n",
    "           if not any([todoFile.split('/')[-1].split('.')[0] in szokeresoOutput for szokeresoOutput in outputFiles])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
