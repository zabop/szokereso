{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary imports\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import pathlib\n",
    "from collections import ChainMap\n",
    "import os\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def didMoreThanThisManySecondsElapsedSinceEndOfThatDay(singleDate,seconds):\n",
    "    '''\n",
    "    datetime.datetime.now() returns an object like this:\n",
    "        datetime.datetime(2020, 8, 17, 9, 26, 21, 78730)\n",
    "\n",
    "    '''\n",
    "    return (datetime.datetime.now() - (singleDate + datetime.timedelta(days=1))).total_seconds() > seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis file looks like this: https://raw.githubusercontent.com/zabop/szokeresoDocs/master/howTheSzotarLooksLike.png\\nIt has some tabs, each tab contains rows, some rows have more than one non-constant number of non-empty columns.\\n\\nThe reason it is stored as an excel file is that non-python people need to access & modify it sometimes.\\n\\nKeep an eye on: if tab names include spaces, ie \"Momentum     \", it will not be obvious from looking at the file in Excel.\\nDon\\'t put spaces there, but if coworkers accidentaly do, that might cause problems which need to be looked into.\\nThe current version of the file is ok, without extra spaces.\\n'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excelFile='/mnt/volume/jupyter/szokereso/vip_szotar_1.4.xlsx'\n",
    "\n",
    "'''\n",
    "This file looks like this: https://raw.githubusercontent.com/zabop/szokeresoDocs/master/howTheSzotarLooksLike.png\n",
    "It has some tabs, each tab contains rows, some rows have more than one non-constant number of non-empty columns.\n",
    "\n",
    "The reason it is stored as an excel file is that non-python people need to access & modify it sometimes.\n",
    "\n",
    "Keep an eye on: if tab names include spaces, ie \"Momentum     \", it will not be obvious from looking at the file in Excel.\n",
    "Don't put spaces there, but if coworkers accidentaly do, that might cause problems which need to be looked into.\n",
    "The current version of the file is ok, without extra spaces.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSearchListFromTabName(tabName,pathToExcelFile=excelFile):    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Example usage: getSearchListFromTabName('LMP') returns:\n",
    "\n",
    "    [['LMP', 'Lehet Más A Politika'],\n",
    "     ['Csárdi Antal', 'Csárdi'],\n",
    "     ['Demeter Márta', 'Demeter'],\n",
    "     ['Ungár Péter', 'Ungár']]\n",
    "\n",
    "    The excel file on the LMP tab looks like this, compare:\n",
    "    https://raw.githubusercontent.com/zabop/szokeresoDocs/master/howTheSzotarLooksLike.png\n",
    "\n",
    "    pd.ExcelFile() reads in the whole excel file, with all tabs.\n",
    "\n",
    "    dfs is a dict created with a dict comprehension.\n",
    "    Keys are tab names of the excel file.\n",
    "    Values are the list of lists, one shown above. \n",
    "\n",
    "    xl.parse(sheetname.header=None) returns a dataframe.\n",
    "    If not all rows have equal number of columns, nans will appear.\n",
    "    For example: xl.parse('MSZP',header=None).values.tolist() returns:\n",
    "\n",
    "    [['MSZP', 'Magyar Szocialista Párt', nan, 'Szocik'],\n",
    "     ['Ujhelyi István', 'Ujhelyi', nan, nan],\n",
    "     ['Kunhalmi Ágnes', 'Kunhalmi', nan, nan],\n",
    "     ['Hiller István', 'Hiller', nan, nan],\n",
    "     ['Molnár Gyula', nan, nan, nan],\n",
    "     ['Bangóné Borbély Ildikó', 'Bangóné', nan, nan],\n",
    "     ['Mesterházy Attila', 'Mesterházy', nan, nan],\n",
    "     ['Tóth Bertalan', nan, nan, nan],\n",
    "     ['Tóth Csaba', nan, nan, nan],\n",
    "     ['Tüttő Kata', 'Tüttő', nan, nan]]\n",
    "\n",
    "    The MSZP tab looks like this in the original excel file:\n",
    "    https://raw.githubusercontent.com/zabop/szokeresoDocs/master/tabMSZP.PNG\n",
    "    We can see that C1 is unreasonably left blank, but so the first line includes a nan in the third place.\n",
    "    There are other nans too, which we wouldn't want to return.\n",
    "\n",
    "    for person in xl.parse(sheetname,header=None).values.tolist() is looping through each list.\n",
    "    Ie first item:\n",
    "    ['MSZP', 'Magyar Szocialista Párt', nan, 'Szocik']\n",
    "    second item:\n",
    "    ['Ujhelyi István', 'Ujhelyi', nan, nan].\n",
    "\n",
    "    [alias for alias in person if type(alias) is not float] is looping through these lists.\n",
    "    Ie first item:\n",
    "    MSZP\n",
    "    second item:\n",
    "    'Magyar Szocialista Párt'\n",
    "    third item:\n",
    "    nan.\n",
    "\n",
    "    The result of this inner list comprehension is a list not containing nans, by the filtering them out: if not float.\n",
    "\n",
    "    dfs will contain this for every tab of the excel file. We only return one value of the dfs dict.\n",
    "\n",
    "    getSearchListFromTabName('MSZP') will return:\n",
    "    [['MSZP', 'Magyar Szocialista Párt', 'Szocik'],\n",
    "     ['Ujhelyi István', 'Ujhelyi'],\n",
    "     ['Kunhalmi Ágnes', 'Kunhalmi'],\n",
    "     ['Hiller István', 'Hiller'],\n",
    "     ['Molnár Gyula'],\n",
    "     ['Bangóné Borbély Ildikó', 'Bangóné'],\n",
    "     ['Mesterházy Attila', 'Mesterházy'],\n",
    "     ['Tóth Bertalan'],\n",
    "     ['Tóth Csaba'],\n",
    "     ['Tüttő Kata', 'Tüttő']]\n",
    "\n",
    "    We are doing more calculation than strictly needed.\n",
    "    We are returning only one value from a dict, but creating the whole dict.\n",
    "    This isn't a performance-limiting issue though, as this operation is performed once per tab.\n",
    "    The potential runtime gain by doing this better is in the order of, so we don't care.\n",
    "\n",
    "    (If bothered, try tabName == sheetname at the end of dict comprehension, but haven't tested this.)\n",
    "\n",
    "    The commented out line after DONT DO THIS includes a .dropna(), which is not behaving as would be desired here.\n",
    "    It drops every row with a nan, the entire row, not just the nans from it.\n",
    "    '''\n",
    "    \n",
    "    pathToExcelFile=excelFile\n",
    "    xl = pd.ExcelFile(pathToExcelFile)\n",
    "    #DONT DO THIS:\n",
    "    #dfs = {sheetname: xl.parse(sheetname, header=None).dropna().values.tolist() for sheetname in xl.sheet_names}\n",
    "    dfs = {sheetname: [[alias for alias in person if type(alias) is not float]\n",
    "                              for person in xl.parse(sheetname,header=None).values.tolist()]\n",
    "                              for sheetname in xl.sheet_names}\n",
    "    return dfs[tabName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def validalias(alias):    \n",
    "    '''\n",
    "    The lines commented out were used at an earlier stage of the project.\n",
    "    Some dictionaries contained aliases which we didn't want to use.\n",
    "\n",
    "    (By dictionaries I mean list of entities, each entity having different names, ie 'MSZP', 'Magyar Szocialista Párt', 'Szocik'.\n",
    "    The different aliases in this case is 'MSZP', 'Magyar Szocialista Párt', 'Szocik', entity is: 'MSZP')\n",
    "\n",
    "    We filetered them with conditions:\n",
    "\n",
    "    - it had to be longer than 5 characters without trailing and leading spaces\n",
    "    - it had to be at least a bigram, ie at least one space between first and last non-space character\n",
    "\n",
    "    Ilénke wouldn't have been a valid alias, Nagy Ilén would've been.\n",
    "\n",
    "    Left here if needed in future, now everything is taken as a valid alias (that's why return True).\n",
    "    '''\n",
    "    return True\n",
    "   # if len(str(alias).strip()) > 5 and len(str(alias).strip().split(' ')) > 1: return True\n",
    "   # else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchfinder(text,searchforthese):    \n",
    "    '''\n",
    "    This function uses list comprehensions on nested lists.\n",
    "    A good visualization on how that works: https://i.stack.imgur.com/0GoV5.gif\n",
    "    From here: https://stackoverflow.com/a/45079294/8565438. I recommend to understand this answer.\n",
    "\n",
    "    We iterate through searchforthese, which is a list of alias lists, ie:\n",
    "\n",
    "    [['LMP', 'Lehet Más A Politika'],\n",
    "     ['Csárdi Antal', 'Csárdi'],\n",
    "     ['Demeter Márta', 'Demeter'],\n",
    "     ['Ungár Péter', 'Ungár']]\n",
    "\n",
    "    persondata_searchtarget is the individual alias lists, (ie ['LMP', 'Lehet Más A Politika'], then ['Csárdi Antal', 'Csárdi']).\n",
    "    We iterate through these (ie take LMP, then Lehet Más A Politika) & check for conditions.\n",
    "\n",
    "    If these conditions are fulfilled, the alias which fulfilled those conditions will be part of mathces.\n",
    "\n",
    "    These contitions:\n",
    "    The alias should be a valid alias (ie validalias(alias) should be True)\n",
    "    alias.lower() in str(text).lower() should be True.\n",
    "\n",
    "    'ElEfÁnT'.lower() is elefánt: lowercasing both alias & text is used to avoid inconsistencies in capitalization.\n",
    "    str(np.nan) is 'nan'. It is used in case input data contains nans, which potentially screws up the function.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    matchfinder('LMP, legyen meleg Péter, Csárdi Antal nem csárdi', [['LMP', 'Lehet Más A Politika'],\n",
    "                                                                     ['Csárdi Antal', 'Csárdi'],\n",
    "                                                                     ['Demeter Márta', 'Demeter'],\n",
    "                                                                     ['Ungár Péter', 'Ungár']])\n",
    "\n",
    "    Returns: ['LMP', 'Csárdi Antal', 'Csárdi'].\n",
    "\n",
    "    We see that occasionally we detect a false positive: here, be returning csárdi.\n",
    "    If we don't lowercase everything, we'll have false negatives.\n",
    "    Make your choices.\n",
    "    '''    \n",
    "    matches=[alias\n",
    "             for persondata_searchtarget in searchforthese\n",
    "             for alias in persondata_searchtarget\n",
    "             if validalias(alias) and alias.lower() in str(text).lower()]\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dictionary_class:\n",
    "    '''\n",
    "    Each dictionary has a name, maxcolnum, searchlist, geo attributes.\n",
    "    \n",
    "    name: the name of the dictionary\n",
    "    \n",
    "    maxcolnum: the maximum number of different entries we want to find in a text\n",
    "    If we find more, we will say we haven't found any of them.\n",
    "    (This is to tackle texts which were signed by a lot of people but is not about those people.)\n",
    "    searchlist is the list of alias lists, ie:\n",
    "    \n",
    "     [['LMP', 'Lehet Más A Politika'],\n",
    "      ['Csárdi Antal', 'Csárdi'],\n",
    "      ['Demeter Márta', 'Demeter'],\n",
    "      ['Ungár Péter', 'Ungár']]\n",
    "    \n",
    "    geo is a boolean, refering to a dictionary containing geographical names.\n",
    "    They are treated differently to people's names sometimes.\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, name, maxcolnum, searchlist=None, geo=False):\n",
    "        self.name = name\n",
    "        self.maxcolnum = maxcolnum\n",
    "        self.searchlist = searchlist\n",
    "        self.geo = geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_sorted_by_date_after_a_date(look_for_this_pattern, cutoffdate):\n",
    "    \n",
    "    '''\n",
    "    look_for_this_pattern should be a wildcard, ie: '/mnt/volume/anagy/mediascraper/mediaScraper/output/data*csv'\n",
    "    cutoffdate should be a list in the format of [year, month, day, 0], ie: [2020,7,1,0]\n",
    "    \n",
    "    csvs will be a list of files like this, with the example look_for_this_pattern wildcard above:\n",
    "    \n",
    "    ['/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-08-17_16:01:34.csv',\n",
    "     '/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-27_06:00:42.csv',\n",
    "     '/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-26_22:00:58.csv',\n",
    "     ...]\n",
    "     \n",
    "    These are the scraped input files.\n",
    "    They are generated every two hours.\n",
    "    data_2020-07-26_22:00:58.csv was generated (roughly) at 2020 July 22th 22h, & it took 00:58 to produce the file.\n",
    "     \n",
    "    re.findall(r'\\d+', each) finds all the digits in the variable each.\n",
    "    Source: https://stackoverflow.com/a/4289348/8565438\n",
    "\n",
    "    Examples:\n",
    "    \n",
    "    re.findall(r'\\d+', 'A 3 kismalac és az 1 farkas meséjének 10edik változata')\n",
    "    returns:\n",
    "    ['3', '1', '10']\n",
    "    \n",
    "    re.findall(r'\\d+', '/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-08-17_16:01:34.csv')\n",
    "    returns:\n",
    "    ['2020', '08', '17', '16', '01', '34']\n",
    "    \n",
    "    \n",
    "    |   !!!WARNING!!!:\n",
    "    |   DO NOT USE NUMERAL CHARACTERS IN PATH LEADING TO INPUT FILES.\n",
    "    |   For example:\n",
    "    |   re.findall(r'\\d+', '/mnt/volume/anagy/mediascraper/mediaScraper/output2/data_2020-08-17_16:01:34.csv')\n",
    "    |   returns:\n",
    "    |   ['2', '2020', '08', '17', '16', '01', '34']\n",
    "    |   The '2' in the front is clearly not what we want.\n",
    "    \n",
    "    \n",
    "    The inner list comprehension converts these to ints.\n",
    "    The first 4 element of this list is what we care about, so we include the [:4].\n",
    "    \n",
    "    datetimes will be a list of datetime.datetime objects, for example, one element of the list can be:\n",
    "    datetime.datetime(2020, 8, 17, 16, 0)\n",
    "    The * used in creation of datetimes list is to unpack argument lists, as described in this answer, for example:\n",
    "    https://stackoverflow.com/a/36908/8565438\n",
    "    \n",
    "    dt_csvs_filtered will be a list of lists.\n",
    "    These lists will contain a datetime.datetime object & the csv file it was created from.\n",
    "    dt_csvs_filtered will only contain those lists which had a datetime.datetime object in them satisfying a condition.\n",
    "    Condition: datetime.datetime object within list must reference a later point in time than datetime.datetime(*cutoffdate).\n",
    "    \n",
    "    sorted_filtered_csvs is the csv filenames from the dt_csvs_filtered list.\n",
    "    They are sorted by chronologically using the datetime.datetime objects within dt_csvs_filtered.\n",
    "    More detailed description here: https://stackoverflow.com/a/6618543/8565438\n",
    "    '''\n",
    "    \n",
    "    csvs = glob.glob(look_for_this_pattern)\n",
    "    datetimes=[datetime.datetime(*[int(num) for num in re.findall(r'\\d+', each)[:4]]) for each in csvs]\n",
    "    dt_csvs_filtered=[[dt, csv] for dt, csv in zip(datetimes,csvs) if dt >= datetime.datetime(*cutoffdate)]\n",
    "    sorted_filtered_csvs = [csv\n",
    "                        for _, csv in sorted(\n",
    "                                         zip([eachpair[0] for eachpair in dt_csvs_filtered],\n",
    "                                             [eachpair[1] for eachpair in dt_csvs_filtered]))]\n",
    "    return sorted_filtered_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathFinder(clientName,path=str(pathlib.Path().absolute())):\n",
    "    '''\n",
    "    This function is to return strings used in paths, filenames, wildcards.\n",
    "    \n",
    "    str(pathlib.Path().absolute()) returns the directory which the code is run from, without final /.\n",
    "    Ie str(pathlib.Path().absolute()):\n",
    "    '/mnt/volume/jupyter/szokereso/negyedikfeladatUjraNegy'\n",
    "    In the same Jupyter Notebook, !pwd is:\n",
    "    /mnt/volume/jupyter/szokereso/negyedikfeladatUjraNegy\n",
    "    '''\n",
    "    \n",
    "    preMomFile = 'live_'\n",
    "    postMomFileSzokereso = '_szokereso_result.csv'\n",
    "    postMomFileSzurt = '_szurt.csv'\n",
    "    postMomFileErrorlog = '_ERRORLOG.txt'\n",
    "\n",
    "    inputPathAndWildcard = '/mnt/volume/anagy/mediascraper/mediaScraper/output/data*csv'\n",
    "    szokeresoResFilesPath =   path+'/'+clientName+'/szokeresores/'\n",
    "    momentumraSzurtSzokeresesPath    = szokeresoResFilesPath + 'clientreszurt/'\n",
    "    szokeresoResFilesPathAndWildcard = momentumraSzurtSzokeresesPath + preMomFile + '*' + postMomFileSzurt\n",
    "\n",
    "    return preMomFile,\\\n",
    "           postMomFileSzokereso,\\\n",
    "           inputPathAndWildcard,\\\n",
    "           postMomFileSzurt,\\\n",
    "           szokeresoResFilesPath,\\\n",
    "           szokeresoResFilesPathAndWildcard,\\\n",
    "           momentumraSzurtSzokeresesPath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis mostly concerns outputting files.\\nOften before df.to_csv() or other functions which output files, there is an if not debugmode clause.\\nHelps not outputting files unnecessarily.\\n'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debugmode = False\n",
    "'''\n",
    "This mostly concerns outputting files.\n",
    "Often before df.to_csv() or other functions which output files, there is an if not debugmode clause.\n",
    "Helps not outputting files unnecessarily.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe want to output only some columns of the dataframe. This list holds the name of those columns.\\n'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfColsWeWantToOutput = ['DOC_ID','TITLE','SCRAPETIME','TEXT','OUTLET','clientdict0clssd', 'clientdict1clssd',\n",
    "                            'clientdict2clssd', 'clientdict3clssd', 'clientdict4clssd', 'clientdict5clssd',\n",
    "                            'clientdict6clssd', 'clientdict7clssd', 'clientdict8clssd', 'clientdict9clssd']\n",
    "'''\n",
    "We want to output only some columns of the dataframe. This list holds the name of those columns.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputFiles(pathAndWildcard):\n",
    "    '''\n",
    "    Returning files the script outputted.\n",
    "    '''\n",
    "    outputFiles = glob.glob(pathAndWildcard)\n",
    "    return outputFiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTodoFilesWithoutOutput(todoFiles,outputFiles):\n",
    "    '''\n",
    "    todoFiles is a list of files which we want to have performed operations on.\n",
    "    outputFiles is a list of files resulting from these operations.\n",
    "    \n",
    "    Example usage:\n",
    "    \n",
    "    getTodoFilesWithoutOutput(todoFiles=['/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_00:00:24.csv',\n",
    "                                     '/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_02:00:18.csv',\n",
    "                                     '/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_04:00:22.csv'],\n",
    "                              outputFiles=['live_data_2020-07-01_00:00:24_szurt.csv'])\n",
    "                              \n",
    "    todoFiles is looped through, & upon fulfilling a condition, each todoFile is put back to the list:\n",
    "    [todoFile for todoFile in todoFiles if condition]\n",
    "    The condition is:\n",
    "    not any([todoFile.split('/')[-1].split('.')[0] in szokeresoOutput for szokeresoOutput in outputFiles])\n",
    "    \n",
    "    If todoFile is: '/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_00:00:24.csv'\n",
    "    todoFile.split('/')[-1].split('.')[0] is: 'data_2020-07-01_00:00:24'\n",
    "    \n",
    "    todoFile.split('/')[-1].split('.')[0] in szokeresoOutput is a boolean.\n",
    "    If szokeresoOutput is 'live_data_2020-07-01_00:00:24_szurt.csv'.\n",
    "    \n",
    "    Example:\n",
    "    'data_2020-07-01_00:00:24' in szokeresoOutput\n",
    "    is evaluated to be True.\n",
    "    \n",
    "    'data_2020-07-01_04:00:22' in szokeresoOutput\n",
    "    is ecaluated to be False.\n",
    "    \n",
    "    By looping through all the outputfiles, we produce a list of booleans:\n",
    "    [todoFile.split('/')[-1].split('.')[0] in szokeresoOutput for szokeresoOutput in outputFiles]\n",
    "    The nth element of this list is True if the nth element of outputFiles is the output corresponding to input file todoFile.\n",
    "    \n",
    "    WARNING: be cautious when renaming outputfiles, not to screw up the functionality of this function.\n",
    "    \n",
    "    If any element of this list if True, there is an output for corresponding to todoFile.\n",
    "    Therefore, we want to return todoFile only if not any of the elements of this list is True:\n",
    "    if not any([todoFile.split('/')[-1].split('.')[0] in szokeresoOutput for szokeresoOutput in outputFiles])]\n",
    "    \n",
    "    for any(), see: https://docs.python.org/3/library/functions.html#any\n",
    "    '''\n",
    "    return [todoFile for todoFile in todoFiles\n",
    "           if not any([todoFile.split('/')[-1].split('.')[0] in szokeresoOutput for szokeresoOutput in outputFiles])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_02:00:18.csv',\n",
       " '/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_04:00:22.csv']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTodoFilesWithoutOutput(todoFiles=['/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_00:00:24.csv',\n",
    "                                     '/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_02:00:18.csv',\n",
    "                                     '/mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_04:00:22.csv'],\n",
    "                          outputFiles=['live_data_2020-07-01_00:00:24_szurt.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_2020-07-01_00:00:24'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todoFiles[0].split('/')[-1].split('.')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "todoFiles=get_files_sorted_by_date_after_a_date('/mnt/volume/anagy/mediascraper/mediaScraper/output/data*csv',[2020,7,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'szokeresoResFilesPathAndWildcard' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-96b40b3b5054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetOutputFiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mszokeresoResFilesPathAndWildcard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'szokeresoResFilesPathAndWildcard' is not defined"
     ]
    }
   ],
   "source": [
    "getOutputFiles(szokeresoResFilesPathAndWildcard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
