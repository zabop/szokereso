{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7v59zIsBA_f"
   },
   "outputs": [],
   "source": [
    "import stanza\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7FZj76mBB-J"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 115kB [00:00, 28.3MB/s]                    \n",
      "2020-07-03 14:32:04 INFO: Downloading default packages for language: hu (Hungarian)...\n",
      "2020-07-03 14:32:04 INFO: File exists: /mnt/volume/jupyter/stanza_resources/hu/default.zip.\n",
      "2020-07-03 14:32:08 INFO: Finished downloading models and saved to /mnt/volume/jupyter/stanza_resources.\n",
      "2020-07-03 14:32:08 INFO: Loading these models for language: hu (Hungarian):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | szeged  |\n",
      "| pos       | szeged  |\n",
      "| lemma     | szeged  |\n",
      "| depparse  | szeged  |\n",
      "=======================\n",
      "\n",
      "2020-07-03 14:32:08 INFO: Use device: cpu\n",
      "2020-07-03 14:32:08 INFO: Loading: tokenize\n",
      "2020-07-03 14:32:08 INFO: Loading: pos\n",
      "2020-07-03 14:32:09 INFO: Loading: lemma\n",
      "2020-07-03 14:32:09 INFO: Loading: depparse\n",
      "2020-07-03 14:32:11 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "stanza.download('hu')\n",
    "nlp = stanza.Pipeline('hu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EfjsL_qSBEk3"
   },
   "outputs": [],
   "source": [
    "def onlywithneighbours(ofthislist):\n",
    "    try:\n",
    "        filtered = [each for each in ofthislist \n",
    "                    if each+1 in ofthislist or each-1 in ofthislist]\n",
    "    except TypeError:\n",
    "        filtered = [each for each in ofthislist \n",
    "                    if str(int(each)+1) in ofthislist or str(int(each)-1) in ofthislist]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEHiWvoGBGQ7"
   },
   "outputs": [],
   "source": [
    "def split_into_numerical_sequences(inlist):\n",
    "\n",
    "    inlist=sorted(inlist)\n",
    "\n",
    "    breakindeces=[i for i,j in enumerate(inlist)\n",
    "                    if (j+1 not in inlist and j in inlist)]\n",
    "\n",
    "    sublists=[]\n",
    "    for index, each in enumerate(breakindeces):\n",
    "        if index==0:\n",
    "            sublists.append([x for x in inlist\n",
    "                               if x<=inlist[each]])\n",
    "        if index!=0:\n",
    "            sublists.append([x for x in inlist\n",
    "                               if x<=inlist[each] and x>inlist[breakindeces[index-1]]])\n",
    "\n",
    "    return sublists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_5rzSZFBBHOx"
   },
   "outputs": [],
   "source": [
    "def stanzanamesearch(text):\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    propns_and_their_positions_dictlist = [{\n",
    "    word.id:word.lemma \n",
    "    for word in sentence.words if word.upos == 'PROPN'}\n",
    "    for sentence in doc.sentences]\n",
    "\n",
    "    propns_with_at_least_one_propn_neighbour = [[\n",
    "    eachdict[eachkey]\n",
    "    for eachkey in sorted(onlywithneighbours(list(eachdict.keys())))]\n",
    "    for eachdict in propns_and_their_positions_dictlist]\n",
    "\n",
    "    propn_ids_with_at_least_one_propn_neighbour = [[\n",
    "    int(eachkey)\n",
    "    for eachkey in sorted(onlywithneighbours(list(eachdict.keys())))]\n",
    "    for eachdict in propns_and_their_positions_dictlist]\n",
    "\n",
    "    propn_id_sequences_with_at_least_one_propn_neighbour=[\n",
    "    split_into_numerical_sequences(eachsublist)\n",
    "    for eachsublist in propn_ids_with_at_least_one_propn_neighbour]\n",
    "\n",
    "    res=[]\n",
    "    for sentenceindex, eachsentence in enumerate(propn_id_sequences_with_at_least_one_propn_neighbour):\n",
    "        for sequenceindex, eachsequence in enumerate(eachsentence):\n",
    "            name=[]\n",
    "            for wordindex, eachword in enumerate(eachsequence):\n",
    "                name.append(propns_and_their_positions_dictlist[sentenceindex][str(eachword)])\n",
    "            name=' '.join(name)\n",
    "            res.append(name)\n",
    "\n",
    "    return list(set(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZ_RaIkpBW58"
   },
   "outputs": [],
   "source": [
    "def validalias(alias):\n",
    "    if len(alias.strip()) > 5 and len(alias.strip().split(' ')) > 1: return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9W4BY3VB7yS"
   },
   "outputs": [],
   "source": [
    "def searchlist_maker(csv,**kwargs):\n",
    "    persondatadict = pd.read_csv(csv)\n",
    "    if 'alias_separator' in kwargs:\n",
    "        persondata_searchlist = [[eachalias.strip()\n",
    "                                for eachalias in eachperson.split(kwargs['alias_separator'])]\n",
    "                                for eachperson in persondatadict['name_list']\n",
    "                                if type(eachperson) != float]\n",
    "    else:\n",
    "        persondata_searchlist = [[each]\n",
    "                                for each in persondatadict['name_list']]\n",
    "    return persondata_searchlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjiAzeh9B9kd"
   },
   "outputs": [],
   "source": [
    "def matchfinder(text,searchforthese):\n",
    "    matches=[alias\n",
    "             for persondata_searchtarget in searchforthese\n",
    "             for alias in persondata_searchtarget\n",
    "             if validalias(alias) and alias.lower() in str(text).lower()]\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uRg_xI4AB_U7"
   },
   "outputs": [],
   "source": [
    "def fillextracols(whichdictionary, whichrowtofill, withthislist, unlessitslongerthanthis):\n",
    "    if not len(withthislist) > unlessitslongerthanthis and len(withthislist)>0:\n",
    "        for i, e in enumerate(withthislist):\n",
    "            targetdf.loc[whichrowtofill,whichdictionary+str(i)]=e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ff5nZfPkCBq9"
   },
   "outputs": [],
   "source": [
    "def prepare_extra_columns(num_of_columns_for_each_dict):\n",
    "    for each in num_of_columns_for_each_dict:\n",
    "        for index in range(num_of_columns_for_each_dict[each]):\n",
    "            targetdf[each + str(index)]=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZ8uL2c-CCn_"
   },
   "outputs": [],
   "source": [
    "class dictionary:\n",
    "    def __init__(self, name, maxcolnum, searchlist=None, trustall=False):\n",
    "        self.name = name\n",
    "        self.maxcolnum = maxcolnum\n",
    "        self.searchlist = searchlist\n",
    "        self.trustall = trustall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mw2hyimiCD1Z"
   },
   "outputs": [],
   "source": [
    "dictionaries=[\n",
    "dictionary('person_data',\n",
    "           10,\n",
    "           searchlist_maker('/mnt/volume/jupyter/szokereso/person_data-1592394309231_utf8.csv',alias_separator='|')),\n",
    "dictionary('wikilist',\n",
    "           5,\n",
    "           searchlist_maker('/mnt/volume/jupyter/szokereso/A_negyedik_Orb√°n-kormany_allamtitkarainak_listaja.csv')),\n",
    "dictionary('stanza',\n",
    "           10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I8WQsjJ2CFRu"
   },
   "outputs": [],
   "source": [
    "targetdf = pd.read_csv('/mnt/volume/jupyter/szokereso/data_2020-06-29_12_01_51.csv')\n",
    "prepare_extra_columns({dictionary.name: dictionary.maxcolnum for dictionary in dictionaries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugmode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656
    },
    "colab_type": "code",
    "id": "iQsmAKxzDi-s",
    "outputId": "cb62f1df-fd29-4be8-9ca6-87378123da81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-941065e4cfa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0micell\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0micell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchlist\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mfillextracols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0micell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatchfinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxcolnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchlist\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mfillextracols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0micell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstanzanamesearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxcolnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-185-2146e82a546e>\u001b[0m in \u001b[0;36mmatchfinder\u001b[0;34m(text, searchforthese)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmatchfinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msearchforthese\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     matches=[alias\n\u001b[0;32m----> 3\u001b[0;31m              \u001b[0;32mfor\u001b[0m \u001b[0mpersondata_searchtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msearchforthese\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m              \u001b[0;32mfor\u001b[0m \u001b[0malias\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpersondata_searchtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              if validalias(alias) and alias.lower() in str(text).lower()]\n",
      "\u001b[0;32m<ipython-input-185-2146e82a546e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m              \u001b[0;32mfor\u001b[0m \u001b[0mpersondata_searchtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msearchforthese\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m              \u001b[0;32mfor\u001b[0m \u001b[0malias\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpersondata_searchtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m              if validalias(alias) and alias.lower() in str(text).lower()]\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cells = list(targetdf['TEXT'])\n",
    "\n",
    "start_time = time.time()\n",
    "for dictionary in dictionaries:\n",
    "    for icell, cell in enumerate(cells):\n",
    "        if icell >60 or not debugmode:\n",
    "            if icell%100==0: print(icell)\n",
    "            if dictionary.searchlist is not None:\n",
    "                fillextracols(dictionary.name,icell,matchfinder(cell,dictionary.searchlist),dictionary.maxcolnum)\n",
    "            if dictionary.searchlist is None:\n",
    "                fillextracols(dictionary.name,icell,stanzanamesearch(cell),dictionary.maxcolnum)\n",
    "end_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPs66OXvFCqe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpfbSeljEKtS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XnewEwNfEKoQ"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vkXv1zMEKwb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vo-ZF0esEKz_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KzjlX_2tCldf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DunelqKFCmWr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oabf--TxD_We"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "szokereso_unified.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
