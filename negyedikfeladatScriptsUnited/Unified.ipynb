{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import pathlib\n",
    "from collections import ChainMap\n",
    "import os\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def didMoreThanThisManySecondsElapsedSinceEndOfThatDay(singleDate,seconds):\n",
    "    return (datetime.datetime.now() - (singleDate + datetime.timedelta(days=1))).total_seconds() > seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile='/mnt/volume/jupyter/szokereso/vip_szotar_1.3.xlsx'\n",
    "\n",
    "def getSearchListFromTabName(tabName,pathToExcelFile=excelFile):\n",
    "    xl = pd.ExcelFile(pathToExcelFile)\n",
    "    dfs = {sheetname:\n",
    "           [[each] for each in xl.parse(sheetname,header=None)[0]]\n",
    "                   for sheetname in xl.sheet_names}\n",
    "    return dfs[tabName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validalias(alias):\n",
    "    return True\n",
    "   # if len(str(alias).strip()) > 5 and len(str(alias).strip().split(' ')) > 1: return True\n",
    "   # else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchfinder(text,searchforthese):\n",
    "    matches=[alias\n",
    "             for persondata_searchtarget in searchforthese\n",
    "             for alias in persondata_searchtarget\n",
    "             if validalias(alias) and alias.lower() in str(text).lower()]\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillextracols(whichdictionary, whichrowtofill, withthislist, unlessitslongerthanthis):\n",
    "    if not len(withthislist) > unlessitslongerthanthis and len(withthislist)>0:\n",
    "        for i, e in enumerate(withthislist):\n",
    "            targetdf.loc[whichrowtofill,whichdictionary+str(i)]=e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_extra_columns(num_of_columns_for_each_dict):\n",
    "    for each in num_of_columns_for_each_dict:\n",
    "        for index in range(num_of_columns_for_each_dict[each]):\n",
    "            targetdf[each + str(index)]=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dictionary_class:\n",
    "    def __init__(self, name, maxcolnum, searchlist=None, geo=False):\n",
    "        self.name = name\n",
    "        self.maxcolnum = maxcolnum\n",
    "        self.searchlist = searchlist\n",
    "        self.geo = geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDictionaries(clientSearchlist,dictname='clientdict'):\n",
    "    dictionaries=[\n",
    "    dictionary_class('clientdict',\n",
    "               10,\n",
    "               clientSearchlist)]\n",
    "    return dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_sorted_by_date_after_a_date(look_for_this_pattern,cutoffdate):\n",
    "    csvs = glob.glob(look_for_this_pattern)\n",
    "    datetimes=[datetime.datetime(int(each.split('/')[-1][5:9]),\n",
    "                             int(each.split('/')[-1][10:12]),\n",
    "                             int(each.split('/')[-1][13:15]),\n",
    "                             int(each.split('/')[-1][16:18]),\n",
    "                             int(each.split('/')[-1][19:21]),\n",
    "                             int(each.split('/')[-1][22:24])) for each in csvs]\n",
    "    dt_csvs_filtered=[[dt, csv] for dt, csv in zip(datetimes,csvs) if dt > datetime.datetime(*cutoffdate)]\n",
    "    sorted_filtered_csvs = [csv\n",
    "                        for _, csv in sorted(\n",
    "                                         zip([eachpair[0] for eachpair in dt_csvs_filtered],\n",
    "                                             [eachpair[1] for eachpair in dt_csvs_filtered]))]\n",
    "    return sorted_filtered_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathFinder(clientName,path=str(pathlib.Path().absolute())):\n",
    "    preMomFile = 'live_updated3_dict_only_1client_'\n",
    "    postMomFileSzokereso = '_szokereso_result.csv'\n",
    "    postMomFileSzurt = '_dfUnifiedNanFilteredOnlySomeColsUpdated3.csv'\n",
    "    postMomFileErrorlog = '_ERRORLOG.txt'\n",
    "\n",
    "    inputPathAndWildcard = '/mnt/volume/anagy/mediascraper/mediaScraper/output/data*csv'\n",
    "    szokeresoResFilesPath =   path+'/'+clientName+'/szokeresores/'\n",
    "    momentumraSzurtSzokeresesPath    = szokeresoResFilesPath + 'clientreszurt/'\n",
    "    szokeresoResFilesPathAndWildcard = momentumraSzurtSzokeresesPath + preMomFile + '*' + postMomFileSzurt\n",
    "\n",
    "    return preMomFile,\\\n",
    "           postMomFileSzokereso,\\\n",
    "           inputPathAndWildcard,\\\n",
    "           postMomFileSzurt,\\\n",
    "           szokeresoResFilesPath,\\\n",
    "           szokeresoResFilesPathAndWildcard,\\\n",
    "           momentumraSzurtSzokeresesPath\n",
    "\n",
    "debugmode = False\n",
    "listOfColsWeWantToOutput = ['DOC_ID','TITLE','SCRAPETIME','TEXT','OUTLET','clientdict0clssd', 'clientdict1clssd',\n",
    "                            'clientdict2clssd', 'clientdict3clssd', 'clientdict4clssd', 'clientdict5clssd',\n",
    "                            'clientdict6clssd', 'clientdict7clssd', 'clientdict8clssd', 'clientdict9clssd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputFiles(pathAndWildcard):\n",
    "    outputFiles = glob.glob(pathAndWildcard)\n",
    "    return outputFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTodoFilesWithoutOutput(todoFiles,outputFiles):\n",
    "    return [todoFile for todoFile in todoFiles\n",
    "           if not any([todoFile.split('/')[-1].split('.')[0] in szokeresoOutput for szokeresoOutput in outputFiles])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doThisWhenNoFileIsFoundToProcess(sleepThisMuch=5*60):\n",
    "    print('No more files found to process. Sleeping '+str(sleepThisMuch)+' seconds.')\n",
    "    time.sleep(sleepThisMuch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equivalences(df, equivalenceClasses):\n",
    "    d = dict(ChainMap(*[dict.fromkeys(y,x) for x , y in equivalenceClasses.items()]))\n",
    "    df = df.replace(d)\n",
    "    df = df.mask(df.apply(pd.Series.duplicated,1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDirectories(sheetNames):\n",
    "    path=str(pathlib.Path().absolute())+'/'\n",
    "    for sheetName in sheetNames:\n",
    "        for subdir in ['clientreszurt','dailyfreqs','weeklyfreqs']:\n",
    "            os.makedirs(path+sheetName+'/'+'szokeresores/'+subdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDict(excelFile=excelFile):\n",
    "    \n",
    "        \n",
    "    xl = pd.ExcelFile(excelFile)\n",
    "    sheetNames = [sheetName.strip() for sheetName in xl.sheet_names]\n",
    "    dfs = {sheetname.strip():\n",
    "           xl.parse(sheetname,header=None)\n",
    "           for sheetname in xl.sheet_names}\n",
    "    \n",
    "    prepareDirectories(sheetNames)\n",
    "        \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEquivalenceClasses(df):\n",
    "    equivalenceClasses = {row[1][0]: list(row[1]) for row in df.iterrows() for alias in row[1]}    \n",
    "    return equivalenceClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/volume/jupyter/szokereso/negyedikfeladatScriptsUnited/KDNP/szokeresores/clientreszurt/live_updated3_dict_only_1client_data_2020-07-01_00:00:24_dfUnifiedNanFilteredOnlySomeColsUpdated3.csv\n",
      "/mnt/volume/jupyter/szokereso/negyedikfeladatScriptsUnited/KDNP/szokeresores/clientreszurt/live_updated3_dict_only_1client_data_2020-07-01_00:00:24_dfUnifiedNanFilteredOnlySomeColsUpdated3.csv\n",
      "/mnt/volume/jupyter/szokereso/negyedikfeladatScriptsUnited/KDNP/szokeresores/clientreszurt/live_updated3_dict_only_1client_data_2020-07-01_00:00:24_dfUnifiedNanFilteredOnlySomeColsUpdated3.csv\n"
     ]
    }
   ],
   "source": [
    "def szokeresoCore(dfs, client):\n",
    "\n",
    "    preMomFile,\\\n",
    "    postMomFileSzokereso,\\\n",
    "    inputPathAndWildcard,\\\n",
    "    postMomFileSzurt,\\\n",
    "    szokeresoResFilesPath,\\\n",
    "    szokeresoResFilesPathAndWildcard,\\\n",
    "    momentumraSzurtSzokeresesPath = pathFinder(client)\n",
    "\n",
    "\n",
    "    while True:\n",
    "\n",
    "\n",
    "        todoFiles=get_files_sorted_by_date_after_a_date(inputPathAndWildcard,[2020,7,1,0])\n",
    "        getOutputFiles(szokeresoResFilesPathAndWildcard)\n",
    "        todoFilesWithoutOutput = getTodoFilesWithoutOutput(todoFiles=todoFiles,\n",
    "                                                           outputFiles=getOutputFiles(szokeresoResFilesPathAndWildcard))\n",
    "        if len(todoFilesWithoutOutput) == 0:\n",
    "            doThisWhenNoFileIsFoundToProcess()\n",
    "            continue\n",
    "\n",
    "        targetcsv=todoFilesWithoutOutput[0]\n",
    "\n",
    "        targetdf = pd.read_csv(targetcsv)\n",
    "        dictionaries=getDictionaries(clientSearchlist=getSearchListFromTabName(tabName=client))\n",
    "\n",
    "\n",
    "        num_of_columns_for_each_dict={dictionary.name: dictionary.maxcolnum for dictionary in dictionaries}\n",
    "        for each in num_of_columns_for_each_dict:\n",
    "            for index in range(num_of_columns_for_each_dict[each]):\n",
    "                targetdf[each + str(index)]=''        \n",
    "\n",
    "\n",
    "        for idictionary, dictionary in enumerate(dictionaries):\n",
    "            for icell, cell in enumerate(list(targetdf['TEXT'])):\n",
    "                if type(cell) is not float:\n",
    "                    if not len(matchfinder(cell,dictionary.searchlist)) > dictionary.maxcolnum \\\n",
    "                    and len(matchfinder(cell,dictionary.searchlist))>0:\n",
    "                        for i, e in enumerate(matchfinder(cell,dictionary.searchlist)):\n",
    "                            targetdf.loc[icell,dictionary.name+str(i)]=e                    \n",
    "\n",
    "        filenamecore = targetcsv.split('/')[-1].split('.')[0]\n",
    "        szokeresoResFilePathAndName=szokeresoResFilesPath+preMomFile+filenamecore+postMomFileSzokereso\n",
    "        targetdf = targetdf[~targetdf['clientdict0'].isna()]\n",
    "\n",
    "        classeddf = equivalences(targetdf[[col for col in targetdf.columns if 'client' in col]],getEquivalenceClasses(dfs[client]))\n",
    "\n",
    "        classeddf.rename(columns={col:col+'clssd' for col in targetdf.columns},inplace=True)\n",
    "        targetdf = targetdf.join(classeddf)\n",
    "\n",
    "        print(momentumraSzurtSzokeresesPath+preMomFile+filenamecore+postMomFileSzurt)\n",
    "        if not debugmode: targetdf[listOfColsWeWantToOutput].to_csv(momentumraSzurtSzokeresesPath+preMomFile+filenamecore+postMomFileSzurt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=prepareDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads={}\n",
    "for client in dfs.keys():\n",
    "    threads[client]=Thread(target=szokeresoCore,args=[dfs,client])\n",
    "    \n",
    "for client in dfs.keys():\n",
    "    threads[client].start()\n",
    "    \n",
    "for client in dfs.keys():\n",
    "    threads[client].join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
