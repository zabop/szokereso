{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = pd.ExcelFile('/mnt/volume/jupyter/szokereso/vip_szotar_1.2.xlsx')\n",
    "dfs = {sheetname.strip():\n",
    "       xl.parse(sheetname,header=None)\n",
    "       for sheetname in xl.sheet_names\n",
    "       if 'Momentum' not in sheetname}\n",
    "\n",
    "equivalenceClasses = {row[1][0]: list(row[1]) for row in dfs[clientName].iterrows() for alias in row[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheetNames = [sheetName.strip() for sheetName in xl.sheet_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.9\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=str(pathlib.Path().absolute())\n",
    "clientName = 'KDNP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/volume/jupyter/szokereso/negyedikfeladatScriptsUnited'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheetName in sheetNames:\n",
    "    for subdir in ['clientreszurt','dailyfreqs','weeklyfreqs']:\n",
    "        os.makedirs(path+sheetName+'/'+'szokeresores/'+subdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/volume/jupyter/szokereso/negyedikfeladatScriptsUnited'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisMuch=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait1(thisMuch):\n",
    "    time.sleep(thisMuch)\n",
    "def wait2(thisMuch):\n",
    "    print('hw')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVariable(a):\n",
    "    for _ in range(5):\n",
    "        time.sleep(1)\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0=Thread(target=getVariable, args=[3])\n",
    "t1=Thread(target=getVariable, args=[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "t0.start()\n",
    "t1.start()\n",
    "\n",
    "\n",
    "\n",
    "t0.join()\n",
    "t1.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def didMoreThanThisManySecondsElapsedSinceEndOfThatDay(singleDate,seconds):\n",
    "    return (datetime.datetime.now() - (singleDate + datetime.timedelta(days=1))).total_seconds() > seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import datetime\n",
    "import glob\n",
    "import stanza\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import pathlib\n",
    "from collections import ChainMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSearchListFromTabName(tabName,pathToExcelFile='/mnt/volume/jupyter/szokereso/vip_szotar_1.2.xlsx'):\n",
    "    xl = pd.ExcelFile(pathToExcelFile)\n",
    "    dfs = {sheetname:\n",
    "           [[each] for each in xl.parse(sheetname,header=None)[0]]\n",
    "                   for sheetname in xl.sheet_names\n",
    "                   if 'Momentum' not in sheetname}\n",
    "    return dfs[tabName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validalias(alias):\n",
    "    return True\n",
    "   # if len(str(alias).strip()) > 5 and len(str(alias).strip().split(' ')) > 1: return True\n",
    "   # else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchfinder(text,searchforthese):\n",
    "    matches=[alias\n",
    "             for persondata_searchtarget in searchforthese\n",
    "             for alias in persondata_searchtarget\n",
    "             if validalias(alias) and alias.lower() in str(text).lower()]\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillextracols(whichdictionary, whichrowtofill, withthislist, unlessitslongerthanthis):\n",
    "    if not len(withthislist) > unlessitslongerthanthis and len(withthislist)>0:\n",
    "        for i, e in enumerate(withthislist):\n",
    "            targetdf.loc[whichrowtofill,whichdictionary+str(i)]=e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_extra_columns(num_of_columns_for_each_dict):\n",
    "    for each in num_of_columns_for_each_dict:\n",
    "        for index in range(num_of_columns_for_each_dict[each]):\n",
    "            targetdf[each + str(index)]=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dictionary_class:\n",
    "    def __init__(self, name, maxcolnum, searchlist=None, geo=False):\n",
    "        self.name = name\n",
    "        self.maxcolnum = maxcolnum\n",
    "        self.searchlist = searchlist\n",
    "        self.geo = geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDictionaries(clientSearchlist,dictname='clientdict'):\n",
    "    dictionaries=[\n",
    "    dictionary_class('clientdict',\n",
    "               10,\n",
    "               clientSearchlist)]\n",
    "    return dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_sorted_by_date_after_a_date(look_for_this_pattern,cutoffdate):\n",
    "    csvs = glob.glob(look_for_this_pattern)\n",
    "    datetimes=[datetime.datetime(int(each.split('/')[-1][5:9]),\n",
    "                             int(each.split('/')[-1][10:12]),\n",
    "                             int(each.split('/')[-1][13:15]),\n",
    "                             int(each.split('/')[-1][16:18]),\n",
    "                             int(each.split('/')[-1][19:21]),\n",
    "                             int(each.split('/')[-1][22:24])) for each in csvs]\n",
    "    dt_csvs_filtered=[[dt, csv] for dt, csv in zip(datetimes,csvs) if dt > datetime.datetime(*cutoffdate)]\n",
    "    sorted_filtered_csvs = [csv\n",
    "                        for _, csv in sorted(\n",
    "                                         zip([eachpair[0] for eachpair in dt_csvs_filtered],\n",
    "                                             [eachpair[1] for eachpair in dt_csvs_filtered]))]\n",
    "    return sorted_filtered_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugmode = False\n",
    "\n",
    "def pathFinder(clientName)\n",
    "\n",
    "preMomFile = 'live_updated3_dict_onlymomentum_'\n",
    "preMomFile = 'live_updated3_dict_only_1client_'\n",
    "postMomFileSzokereso = '_szokereso_result.csv'\n",
    "postMomFileSzurt = '_dfUnifiedNanFilteredOnlySomeColsUpdated3.csv'\n",
    "postMomFileErrorlog = '_ERRORLOG.txt'\n",
    "\n",
    "inputPathAndWildcard = '/mnt/volume/anagy/mediascraper/mediaScraper/output/data*csv'\n",
    "szokeresoResFilesPath =   path+clientName+'/szokeresores/'\n",
    "szokeresoResFilesPathAndWildcard = szokeresoResFilesPath + preMomFile + '*' + postMomFileSzokereso\n",
    "momentumraSzurtSzokeresesPath    = szokeresoResFilesPath + 'clientreszurt/'\n",
    "\n",
    "\n",
    "listOfColsWeWantToOutput = ['DOC_ID','TITLE','SCRAPETIME','TEXT','OUTLET','clientdict0clssd', 'clientdict1clssd',\n",
    "                            'clientdict2clssd', 'clientdict3clssd', 'clientdict4clssd', 'clientdict5clssd',\n",
    "                            'clientdict6clssd', 'clientdict7clssd', 'clientdict8clssd', 'clientdict9clssd']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/volume/jupyter/szokereso/negyedikfeladatScriptsUnitedKDNP/szokeresores/'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "szokeresoResFilesPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KDNP'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clientName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputFiles(pathAndWildcard=szokeresoResFilesPathAndWildcard):\n",
    "    outputFiles = glob.glob(pathAndWildcard)\n",
    "    return outputFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTodoFilesWithoutOutput(todoFiles,outputFiles=getOutputFiles()):\n",
    "    return [todoFile for todoFile in todoFiles\n",
    "           if not any([todoFile.split('/')[-1].split('.')[0] in szokeresoOutput for szokeresoOutput in getOutputFiles()])]\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "def doThisWhenNoFileIsFoundToProcess(sleepThisMuch=5*60):\n",
    "    print('No more files found to process. Sleeping '+str(sleepThisMuch)+' seconds.')\n",
    "    time.sleep(sleepThisMuch)\n",
    "\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "\n",
    "def equivalences(df, equivalenceClasses):\n",
    "    d = dict(ChainMap(*[dict.fromkeys(y,x) for x , y in equivalenceClasses.items()]))\n",
    "    df = df.replace(d)\n",
    "    df = df.mask(df.apply(pd.Series.duplicated,1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: /mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_02:00:18.csv\n",
      "processing: /mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_04:00:22.csv\n",
      "processing: /mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_06:00:26.csv\n",
      "processing: /mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_08:01:18.csv\n"
     ]
    }
   ],
   "source": [
    "client='KDNP'\n",
    "\n",
    "while True:\n",
    "\n",
    "    todoFiles=get_files_sorted_by_date_after_a_date(inputPathAndWildcard,[2020,7,1,0])\n",
    "    todoFilesWithoutOutput = getTodoFilesWithoutOutput(todoFiles)\n",
    "\n",
    "    if len(todoFilesWithoutOutput) == 0:\n",
    "        doThisWhenNoFileIsFoundToProcess()\n",
    "        continue\n",
    "\n",
    "    print('processing: '+todoFilesWithoutOutput[0])    \n",
    "\n",
    "    targetcsv=todoFilesWithoutOutput[0]\n",
    "    try:\n",
    "        targetdf = pd.read_csv(targetcsv)\n",
    "        dictionaries=getDictionaries(clientSearchlist=getSearchListFromTabName(tabName=client))\n",
    "        prepare_extra_columns({dictionary.name: dictionary.maxcolnum for dictionary in dictionaries})\n",
    "        for idictionary, dictionary in enumerate(dictionaries):\n",
    "            for icell, cell in enumerate(list(targetdf['TEXT'])):\n",
    "                if type(cell) is not float:\n",
    "                    if dictionary.searchlist is not None:\n",
    "                        fillextracols(dictionary.name,icell,matchfinder(cell,dictionary.searchlist),dictionary.maxcolnum)\n",
    "                    if dictionary.searchlist is None:\n",
    "                        fillextracols(dictionary.name,icell,stanzanamesearch(cell),dictionary.maxcolnum)\n",
    "\n",
    "        filenamecore = targetcsv.split('/')[-1].split('.')[0]\n",
    "        szokeresoResFilePathAndName=szokeresoResFilesPath+preMomFile+filenamecore+postMomFileSzokereso\n",
    "\n",
    "        if not debugmode:\n",
    "            targetdf.to_csv(szokeresoResFilePathAndName)\n",
    "\n",
    "        df = pd.read_csv(szokeresoResFilePathAndName)\n",
    "        df = df[~df['clientdict0'].isna()]\n",
    "\n",
    "        classeddf = equivalences(df[[col for col in df.columns if 'client' in col]],equivalenceClasses)\n",
    "        classeddf.rename(columns={col:col+'clssd' for col in df.columns},inplace=True)\n",
    "        df = df.join(classeddf)\n",
    "\n",
    "        if not debugmode: df[listOfColsWeWantToOutput].to_csv(momentumraSzurtSzokeresesPath+preMomFile+filenamecore+postMomFileSzurt)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "   # except:\n",
    "   #     print('exception occured')\n",
    "   #     the_type, the_value, the_traceback = sys.exc_info()\n",
    "   #     outlist = [the_type, the_value, targetcsv, dictionary.name, icell]\n",
    "   #     if not debugmode:\n",
    "   #         with open(szokeresoResFilePathAndName+postMomFileErrorlog, 'w') as f:\n",
    "   #             for item in outlist:\n",
    "   #                 f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
