{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import datetime\n",
    "import glob\n",
    "import stanza\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import pathlib\n",
    "from collections import ChainMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=str(pathlib.Path().absolute())\n",
    "clientName = path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = pd.ExcelFile('/mnt/volume/jupyter/szokereso/vip_szotar_1.2.xlsx')\n",
    "dfs = {sheetname:\n",
    "       xl.parse(sheetname,header=None)\n",
    "       for sheetname in xl.sheet_names\n",
    "       if 'Momentum' not in sheetname}\n",
    "\n",
    "equivalenceClasses = {row[1][0]: list(row[1]) for row in dfs[clientName].iterrows() for alias in row[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSearchListFromTabName(pathToExcelFile,tabName):\n",
    "    xl = pd.ExcelFile('/mnt/volume/jupyter/szokereso/vip_szotar_1.1.xlsx')\n",
    "    dfs = {sheetname:\n",
    "           [[each] for each in xl.parse(sheetname,header=None)[0]]\n",
    "                   for sheetname in xl.sheet_names\n",
    "                   if 'Momentum' not in sheetname}\n",
    "    return dfs[tabName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientSearchlist = getSearchListFromTabName('/mnt/volume/jupyter/szokereso/vip_szotar_1.1.xlsx',clientName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onlywithneighbours(ofthislist):\n",
    "    try:\n",
    "        filtered = [each for each in ofthislist \n",
    "                    if each+1 in ofthislist or each-1 in ofthislist]\n",
    "    except TypeError:\n",
    "        filtered = [each for each in ofthislist \n",
    "                    if str(int(each)+1) in ofthislist or str(int(each)-1) in ofthislist]\n",
    "    return filtered\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "def split_into_numerical_sequences(inlist):\n",
    "\n",
    "    inlist=sorted(inlist)\n",
    "\n",
    "    breakindeces=[i for i,j in enumerate(inlist)\n",
    "                    if (j+1 not in inlist and j in inlist)]\n",
    "\n",
    "    sublists=[]\n",
    "    for index, each in enumerate(breakindeces):\n",
    "        if index==0:\n",
    "            sublists.append([x for x in inlist\n",
    "                               if x<=inlist[each]])\n",
    "        if index!=0:\n",
    "            sublists.append([x for x in inlist\n",
    "                               if x<=inlist[each] and x>inlist[breakindeces[index-1]]])\n",
    "\n",
    "    return sublists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validalias(alias):\n",
    "    return True\n",
    "   # if len(str(alias).strip()) > 5 and len(str(alias).strip().split(' ')) > 1: return True\n",
    "   # else: return False\n",
    "\n",
    "\n",
    "# In[385]:\n",
    "\n",
    "\n",
    "def matchfinder(text,searchforthese):\n",
    "    matches=[alias\n",
    "             for persondata_searchtarget in searchforthese\n",
    "             for alias in persondata_searchtarget\n",
    "             if validalias(alias) and alias.lower() in str(text).lower()]\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fillextracols(whichdictionary, whichrowtofill, withthislist, unlessitslongerthanthis):\n",
    "    if not len(withthislist) > unlessitslongerthanthis and len(withthislist)>0:\n",
    "        for i, e in enumerate(withthislist):\n",
    "            targetdf.loc[whichrowtofill,whichdictionary+str(i)]=e\n",
    "\n",
    "\n",
    "# In[387]:\n",
    "\n",
    "\n",
    "def prepare_extra_columns(num_of_columns_for_each_dict):\n",
    "    for each in num_of_columns_for_each_dict:\n",
    "        for index in range(num_of_columns_for_each_dict[each]):\n",
    "            targetdf[each + str(index)]=''\n",
    "\n",
    "\n",
    "# In[388]:\n",
    "\n",
    "\n",
    "class dictionary_class:\n",
    "    def __init__(self, name, maxcolnum, searchlist=None, geo=False):\n",
    "        self.name = name\n",
    "        self.maxcolnum = maxcolnum\n",
    "        self.searchlist = searchlist\n",
    "        self.geo = geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries=[\n",
    "dictionary_class('clientdict',\n",
    "           10,\n",
    "           clientSearchlist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_sorted_by_date_after_a_date(look_for_this_pattern,cutoffdate):\n",
    "    \n",
    "    csvs = glob.glob(look_for_this_pattern)\n",
    "    datetimes=[datetime.datetime(int(each.split('/')[-1][5:9]),\n",
    "                             int(each.split('/')[-1][10:12]),\n",
    "                             int(each.split('/')[-1][13:15]),\n",
    "                             int(each.split('/')[-1][16:18]),\n",
    "                             int(each.split('/')[-1][19:21]),\n",
    "                             int(each.split('/')[-1][22:24])) for each in csvs]\n",
    "\n",
    "    dt_csvs_filtered=[[dt, csv] for dt, csv in zip(datetimes,csvs) if dt > datetime.datetime(*cutoffdate)]\n",
    "    \n",
    "    sorted_filtered_csvs = [csv\n",
    "                        for _, csv in sorted(\n",
    "                                         zip([eachpair[0] for eachpair in dt_csvs_filtered],\n",
    "                                             [eachpair[1] for eachpair in dt_csvs_filtered]))]\n",
    "    \n",
    "    return sorted_filtered_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugmode = False\n",
    "\n",
    "preMomFile = 'live_updated3_dict_onlymomentum_'\n",
    "preMomFile = 'live_updated3_dict_only_1client_'\n",
    "postMomFileSzokereso = '_szokereso_result.csv'\n",
    "postMomFileSzurt = '_dfUnifiedNanFilteredOnlySomeColsUpdated3.csv'\n",
    "postMomFileErrorlog = '_ERRORLOG.txt'\n",
    "\n",
    "inputPathAndWildcard = '/mnt/volume/anagy/mediascraper/mediaScraper/output/data*csv'\n",
    "szokeresoResFilesPath =   '/mnt/volume/jupyter/szokereso/negyedikfeladatOsszevonasokkal/'+clientName+'/szokeresores/'\n",
    "szokeresoResFilesPathAndWildcard = szokeresoResFilesPath + preMomFile + '*' + postMomFileSzokereso\n",
    "momentumraSzurtSzokeresesPath    = szokeresoResFilesPath + 'clientreszurt/'\n",
    "\n",
    "\n",
    "listOfColsWeWantToOutput = ['DOC_ID','TITLE','SCRAPETIME','TEXT','OUTLET','clientdict0clssd', 'clientdict1clssd',\n",
    "                            'clientdict2clssd', 'clientdict3clssd', 'clientdict4clssd', 'clientdict5clssd',\n",
    "                            'clientdict6clssd', 'clientdict7clssd', 'clientdict8clssd', 'clientdict9clssd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputFiles(pathAndWildcard=szokeresoResFilesPathAndWildcard):\n",
    "    outputFiles = glob.glob(pathAndWildcard)\n",
    "    return outputFiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTodoFilesWithoutOutput(todoFiles,outputFiles=getOutputFiles()):\n",
    "    return [todoFile for todoFile in todoFiles\n",
    "           if not any([todoFile.split('/')[-1].split('.')[0] in szokeresoOutput for szokeresoOutput in getOutputFiles()])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doThisWhenNoFileIsFoundToProcess(sleepThisMuch=5*60):\n",
    "    print('No more files found to process. Sleeping '+str(sleepThisMuch)+' seconds.')\n",
    "    time.sleep(sleepThisMuch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equivalences(df, equivalenceClasses):\n",
    "    d = dict(ChainMap(*[dict.fromkeys(y,x) for x , y in equivalenceClasses.items()]))\n",
    "    df = df.replace(d)\n",
    "    df = df.mask(df.apply(pd.Series.duplicated,1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: /mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_10:02:51.csv\n",
      "processing: /mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_12:00:43.csv\n",
      "processing: /mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_14:02:26.csv\n",
      "processing: /mnt/volume/anagy/mediascraper/mediaScraper/output/data_2020-07-01_15:13:04.csv\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "\n",
    "    todoFiles=get_files_sorted_by_date_after_a_date(inputPathAndWildcard,[2020,7,1,0])\n",
    "    todoFilesWithoutOutput = getTodoFilesWithoutOutput(todoFiles)\n",
    "    \n",
    "    if len(todoFilesWithoutOutput) == 0:\n",
    "        doThisWhenNoFileIsFoundToProcess()\n",
    "        continue\n",
    "        \n",
    "    print('processing: '+todoFilesWithoutOutput[0])    \n",
    "\n",
    "    targetcsv=todoFilesWithoutOutput[0]\n",
    "    try:\n",
    "        targetdf = pd.read_csv(targetcsv)\n",
    "        prepare_extra_columns({dictionary.name: dictionary.maxcolnum for dictionary in dictionaries})\n",
    "        for idictionary, dictionary in enumerate(dictionaries):\n",
    "            for icell, cell in enumerate(list(targetdf['TEXT'])):\n",
    "                if type(cell) is not float:\n",
    "                    if dictionary.searchlist is not None:\n",
    "                        fillextracols(dictionary.name,icell,matchfinder(cell,dictionary.searchlist),dictionary.maxcolnum)\n",
    "                    if dictionary.searchlist is None:\n",
    "                        fillextracols(dictionary.name,icell,stanzanamesearch(cell),dictionary.maxcolnum)\n",
    "        \n",
    "        filenamecore = targetcsv.split('/')[-1].split('.')[0]\n",
    "        szokeresoResFilePathAndName=szokeresoResFilesPath+preMomFile+filenamecore+postMomFileSzokereso\n",
    "        \n",
    "        if not debugmode:\n",
    "            targetdf.to_csv(szokeresoResFilePathAndName)\n",
    "        \n",
    "        df = pd.read_csv(szokeresoResFilePathAndName)\n",
    "        df = df[~df['clientdict0'].isna()]\n",
    "        \n",
    "        classeddf = equivalences(df[[col for col in df.columns if 'client' in col]],equivalenceClasses)\n",
    "        classeddf.rename(columns={col:col+'clssd' for col in df.columns},inplace=True)\n",
    "        df = df.join(classeddf)\n",
    "        \n",
    "        if not debugmode: df[listOfColsWeWantToOutput].to_csv(momentumraSzurtSzokeresesPath+preMomFile+filenamecore+postMomFileSzurt)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:\n",
    "        print('exception occured')\n",
    "        the_type, the_value, the_traceback = sys.exc_info()\n",
    "        outlist = [the_type, the_value, targetcsv, dictionary.name, icell]\n",
    "        if not debugmode:\n",
    "            with open(szokeresoResFilePathAndName+postMomFileErrorlog, 'w') as f:\n",
    "                for item in outlist:\n",
    "                    f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
