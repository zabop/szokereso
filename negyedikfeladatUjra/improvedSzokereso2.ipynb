{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import pathlib\n",
    "from collections import ChainMap\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def didMoreThanThisManySecondsElapsedSinceEndOfThatDay(singleDate,seconds):\n",
    "    return (datetime.datetime.now() - (singleDate + datetime.timedelta(days=1))).total_seconds() > seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFile='/mnt/volume/jupyter/szokereso/vip_szotar_1.3.xlsx'\n",
    "\n",
    "def getSearchListFromTabName(tabName,pathToExcelFile=excelFile):\n",
    "    xl = pd.ExcelFile(pathToExcelFile)\n",
    "    dfs = {sheetname:\n",
    "           [[each] for each in xl.parse(sheetname,header=None)[0]]\n",
    "                   for sheetname in xl.sheet_names}\n",
    "    return dfs[tabName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validalias(alias):\n",
    "    return True\n",
    "   # if len(str(alias).strip()) > 5 and len(str(alias).strip().split(' ')) > 1: return True\n",
    "   # else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchfinder(text,searchforthese):\n",
    "    matches=[alias\n",
    "             for persondata_searchtarget in searchforthese\n",
    "             for alias in persondata_searchtarget\n",
    "             if validalias(alias) and alias.lower() in str(text).lower()]\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillextracols(whichdictionary, whichrowtofill, withthislist, unlessitslongerthanthis):\n",
    "    if not len(withthislist) > unlessitslongerthanthis and len(withthislist)>0:\n",
    "        for i, e in enumerate(withthislist):\n",
    "            targetdf.loc[whichrowtofill,whichdictionary+str(i)]=e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_extra_columns(num_of_columns_for_each_dict):\n",
    "    for each in num_of_columns_for_each_dict:\n",
    "        for index in range(num_of_columns_for_each_dict[each]):\n",
    "            targetdf[each + str(index)]=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dictionary_class:\n",
    "    def __init__(self, name, maxcolnum, searchlist=None, geo=False):\n",
    "        self.name = name\n",
    "        self.maxcolnum = maxcolnum\n",
    "        self.searchlist = searchlist\n",
    "        self.geo = geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDictionaries(clientSearchlist,dictname='clientdict'):\n",
    "    dictionaries=[\n",
    "    dictionary_class('clientdict',\n",
    "               10,\n",
    "               clientSearchlist)]\n",
    "    return dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_sorted_by_date_after_a_date(look_for_this_pattern,cutoffdate):\n",
    "    csvs = glob.glob(look_for_this_pattern)\n",
    "    datetimes=[datetime.datetime(int(each.split('/')[-1][5:9]),\n",
    "                             int(each.split('/')[-1][10:12]),\n",
    "                             int(each.split('/')[-1][13:15]),\n",
    "                             int(each.split('/')[-1][16:18]),\n",
    "                             int(each.split('/')[-1][19:21]),\n",
    "                             int(each.split('/')[-1][22:24])) for each in csvs]\n",
    "    dt_csvs_filtered=[[dt, csv] for dt, csv in zip(datetimes,csvs) if dt > datetime.datetime(*cutoffdate)]\n",
    "    sorted_filtered_csvs = [csv\n",
    "                        for _, csv in sorted(\n",
    "                                         zip([eachpair[0] for eachpair in dt_csvs_filtered],\n",
    "                                             [eachpair[1] for eachpair in dt_csvs_filtered]))]\n",
    "    return sorted_filtered_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathFinder(clientName,path=str(pathlib.Path().absolute())):\n",
    "    preMomFile = 'live_updated3_dict_only_1client_'\n",
    "    postMomFileSzokereso = '_szokereso_result.csv'\n",
    "    postMomFileSzurt = '_dfUnifiedNanFilteredOnlySomeColsUpdated3.csv'\n",
    "    postMomFileErrorlog = '_ERRORLOG.txt'\n",
    "\n",
    "    inputPathAndWildcard = '/mnt/volume/anagy/mediascraper/mediaScraper/output/data*csv'\n",
    "    szokeresoResFilesPath =   path+'/'+clientName+'/szokeresores/'\n",
    "    momentumraSzurtSzokeresesPath    = szokeresoResFilesPath + 'clientreszurt/'\n",
    "    szokeresoResFilesPathAndWildcard = momentumraSzurtSzokeresesPath + preMomFile + '*' + postMomFileSzurt\n",
    "\n",
    "    return preMomFile,\\\n",
    "           postMomFileSzokereso,\\\n",
    "           inputPathAndWildcard,\\\n",
    "           postMomFileSzurt,\\\n",
    "           szokeresoResFilesPath,\\\n",
    "           szokeresoResFilesPathAndWildcard,\\\n",
    "           momentumraSzurtSzokeresesPath\n",
    "\n",
    "debugmode = False\n",
    "listOfColsWeWantToOutput = ['DOC_ID','TITLE','SCRAPETIME','TEXT','OUTLET','clientdict0clssd', 'clientdict1clssd',\n",
    "                            'clientdict2clssd', 'clientdict3clssd', 'clientdict4clssd', 'clientdict5clssd',\n",
    "                            'clientdict6clssd', 'clientdict7clssd', 'clientdict8clssd', 'clientdict9clssd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputFiles(pathAndWildcard):\n",
    "    outputFiles = glob.glob(pathAndWildcard)\n",
    "    return outputFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTodoFilesWithoutOutput(todoFiles,outputFiles):\n",
    "    return [todoFile for todoFile in todoFiles\n",
    "           if not any([todoFile.split('/')[-1].split('.')[0] in szokeresoOutput for szokeresoOutput in outputFiles])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doThisWhenNoFileIsFoundToProcess(sleepThisMuch=5*60):\n",
    "    #print('No more files found to process. Sleeping '+str(sleepThisMuch)+' seconds.')\n",
    "    print('Looped through all clients. Sleeping '+str(sleepThisMuch)+' seconds.')\n",
    "    time.sleep(sleepThisMuch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equivalences(df, equivalenceClasses):\n",
    "    d = dict(ChainMap(*[dict.fromkeys(y,x) for x , y in equivalenceClasses.items()]))\n",
    "    df = df.replace(d)\n",
    "    df = df.mask(df.apply(pd.Series.duplicated,1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDirectories(sheetNames):\n",
    "    path=str(pathlib.Path().absolute())+'/'\n",
    "    for sheetName in sheetNames:\n",
    "        for subdir in ['clientreszurt','dailyfreqs','weeklyfreqs']:\n",
    "            os.makedirs(path+sheetName+'/'+'szokeresores/'+subdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDict(excelFile=excelFile):\n",
    "    \n",
    "        \n",
    "    xl = pd.ExcelFile(excelFile)\n",
    "    sheetNames = [sheetName.strip() for sheetName in xl.sheet_names]\n",
    "    dfs = {sheetname.strip():\n",
    "           xl.parse(sheetname,header=None)\n",
    "           for sheetname in xl.sheet_names}          \n",
    "    prepareDirectories(sheetNames)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEquivalenceClasses(df):\n",
    "    equivalenceClasses = {row[1][0]: list(row[1]) for row in df.iterrows() for alias in row[1]}    \n",
    "    return equivalenceClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looped through all clients. Sleeping 300 seconds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-bd8ca8736b06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdebugmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargetdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlistOfColsWeWantToOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentumraSzurtSzokeresesPath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpreMomFile\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilenamecore\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpostMomFileSzurt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mdoThisWhenNoFileIsFoundToProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-56b0313a2ef0>\u001b[0m in \u001b[0;36mdoThisWhenNoFileIsFoundToProcess\u001b[0;34m(sleepThisMuch)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#print('No more files found to process. Sleeping '+str(sleepThisMuch)+' seconds.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Looped through all clients. Sleeping '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleepThisMuch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' seconds.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleepThisMuch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dfs=prepareDict()\n",
    "clients=list(dfs.keys())\n",
    "\n",
    "while True:\n",
    "    for client in clients:\n",
    "        preMomFile,\\\n",
    "        postMomFileSzokereso,\\\n",
    "        inputPathAndWildcard,\\\n",
    "        postMomFileSzurt,\\\n",
    "        szokeresoResFilesPath,\\\n",
    "        szokeresoResFilesPathAndWildcard,\\\n",
    "        momentumraSzurtSzokeresesPath = pathFinder(client)\n",
    "\n",
    "        while True:\n",
    "            todoFiles=get_files_sorted_by_date_after_a_date(inputPathAndWildcard,[2020,8,10,0])\n",
    "            getOutputFiles(szokeresoResFilesPathAndWildcard)\n",
    "            todoFilesWithoutOutput = getTodoFilesWithoutOutput(todoFiles=todoFiles,\n",
    "                                                               outputFiles=getOutputFiles(szokeresoResFilesPathAndWildcard))\n",
    "            if len(todoFilesWithoutOutput) == 0:\n",
    "                break\n",
    "\n",
    "            targetcsv=todoFilesWithoutOutput[0]\n",
    "\n",
    "            targetdf = pd.read_csv(targetcsv)\n",
    "            dictionaries=getDictionaries(clientSearchlist=getSearchListFromTabName(tabName=client))\n",
    "\n",
    "\n",
    "            num_of_columns_for_each_dict={dictionary.name: dictionary.maxcolnum for dictionary in dictionaries}\n",
    "            for each in num_of_columns_for_each_dict:\n",
    "                for index in range(num_of_columns_for_each_dict[each]):\n",
    "                    targetdf[each + str(index)]=''        \n",
    "\n",
    "\n",
    "            for idictionary, dictionary in enumerate(dictionaries):\n",
    "                for icell, cell in enumerate(list(targetdf['TEXT'])):\n",
    "                    if type(cell) is not float:\n",
    "                        if not len(matchfinder(cell,dictionary.searchlist)) > dictionary.maxcolnum                     and len(matchfinder(cell,dictionary.searchlist))>0:\n",
    "                            for i, e in enumerate(matchfinder(cell,dictionary.searchlist)):\n",
    "                                targetdf.loc[icell,dictionary.name+str(i)]=e                    \n",
    "\n",
    "            filenamecore = targetcsv.split('/')[-1].split('.')[0]\n",
    "            szokeresoResFilePathAndName=szokeresoResFilesPath+preMomFile+filenamecore+postMomFileSzokereso\n",
    "            #targetdf = targetdf[~targetdf['clientdict0'].isna()]\n",
    "            targetdf = targetdf[targetdf['clientdict0'].str.len()>0]\n",
    "            \n",
    "            classeddf = equivalences(targetdf[[col for col in targetdf.columns if 'client' in col]],getEquivalenceClasses(dfs[client]))\n",
    "\n",
    "            classeddf.rename(columns={col:col+'clssd' for col in targetdf.columns},inplace=True)\n",
    "            targetdf = targetdf.join(classeddf)\n",
    "\n",
    "            print(momentumraSzurtSzokeresesPath+preMomFile+filenamecore+postMomFileSzurt)\n",
    "            if not debugmode: targetdf[listOfColsWeWantToOutput].to_csv(momentumraSzurtSzokeresesPath+preMomFile+filenamecore+postMomFileSzurt)\n",
    "\n",
    "    doThisWhenNoFileIsFoundToProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'targetdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3e74c5cf4d43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtargetdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'targetdf' is not defined"
     ]
    }
   ],
   "source": [
    "targetdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#np.random.randint(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probalist = ['A','B','C']\n",
    "#while True:\n",
    "#    counter=0\n",
    "#        \n",
    "#    for x in probalist:\n",
    "#        while True:\n",
    "#            print(counter)\n",
    "#            print(x)\n",
    "#            if np.random.randint(2) == 0:\n",
    "#                print('randomstrike')\n",
    "#                counter+=1\n",
    "#                break\n",
    "#            print('doing stuff with '+x)\n",
    "#            \n",
    "#    if counter==len(probalist):\n",
    "#        print('sleeping 5 secs')\n",
    "#time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
