{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import pathlib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validalias(alias):\n",
    "    if len(str(alias).strip()) > 5 and len(str(alias).strip().split(' ')) > 1: return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchfinder(text,searchforthese):\n",
    "    matches=[alias\n",
    "             for persondata_searchtarget in searchforthese\n",
    "             for alias in persondata_searchtarget\n",
    "             if validalias(alias) and alias.lower() in str(text).lower()]\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dictionary_class:\n",
    "    def __init__(self, name, maxcolnum, searchlist=None, geo=False):\n",
    "        self.name = name\n",
    "        self.maxcolnum = maxcolnum\n",
    "        self.searchlist = searchlist\n",
    "        self.geo = geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchlist_maker(csv,excelfile=False,multisheet=False,columnsfiltered=False, headerwechoose='name_list',**kwargs):\n",
    "    \n",
    "    if not multisheet:\n",
    "        if excelfile: persondatadict = pd.read_excel(csv)\n",
    "\n",
    "        else:\n",
    "            persondatadict = pd.read_csv(csv)\n",
    "\n",
    "        if 'alias_separator' in kwargs:\n",
    "            persondata_searchlist = [[eachalias.strip()\n",
    "                                    for eachalias in eachperson.split(kwargs['alias_separator'])]\n",
    "                                    for eachperson in persondatadict[headerwechoose]\n",
    "                                    if type(eachperson) != float]\n",
    "        else:\n",
    "            persondata_searchlist = [[each]\n",
    "                                    for each in persondatadict[headerwechoose]]\n",
    "\n",
    "    if multisheet:\n",
    "        \n",
    "        if not columnsfiltered:\n",
    "\n",
    "            xls=pd.ExcelFile(csv)\n",
    "            dfs=[pd.read_excel(xls,sheet) for i, sheet in enumerate(xls.sheet_names)]\n",
    "            persondata_searchlist=[[name] for df in dfs for name in df['name_list'] if type(name) is not float]\n",
    "\n",
    "        if columnsfiltered:\n",
    "            \n",
    "            unifieddf=pd.concat([pd.read_excel(csv, sheetname)[column]\n",
    "                        for sheetname in pd.ExcelFile(csv).sheet_names\n",
    "                        for column in pd.read_excel(csv, sheetname)\n",
    "                        if 'LOOKFOR' in column]).dropna().drop_duplicates()\n",
    "            \n",
    "            persondata_searchlist = [[each] for each in unifieddf]\n",
    "            \n",
    "    return persondata_searchlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries=[\n",
    "dictionary_class('person_data',\n",
    "           10,\n",
    "           searchlist_maker('/mnt/volume/jupyter/szokereso/person_data-1592394309231_utf8.csv',alias_separator='|')),\n",
    "dictionary_class('wikilist',\n",
    "           5,\n",
    "           searchlist_maker('/mnt/volume/jupyter/szokereso/A_negyedik_OrbÃ¡n-kormany_allamtitkarainak_listaja.csv')),\n",
    "dictionary_class('stanza',\n",
    "           10),\n",
    "dictionary_class('settlement_list',\n",
    "           5,\n",
    "           searchlist_maker('/mnt/volume/jupyter/szokereso/List of Settlements_m2.xlsx', excelfile=True,headerwechoose='settlement_name'),\n",
    "           geo=True),\n",
    "dictionary_class('szotar_2.1',\n",
    "           10,\n",
    "           searchlist_maker('/mnt/volume/jupyter/szokereso/szotar_2.1.xlsx',multisheet=True)),\n",
    "dictionary_class('instit_dict',\n",
    "            10,\n",
    "            searchlist_maker('/mnt/volume/jupyter/szokereso/instit_dict_2.1_updated_headers.xlsx',\n",
    "                             multisheet=True,\n",
    "                             columnsfiltered=True)),\n",
    "dictionary_class('geo2dict',\n",
    "                10,\n",
    "                searchlist_maker('/mnt/volume/jupyter/szokereso/geo2.csv',\n",
    "                             multisheet=False,\n",
    "                             columnsfiltered=False,\n",
    "                             alias_separator='|')),\n",
    "dictionary_class('corporate2dict',\n",
    "                 10,\n",
    "                 searchlist_maker('/mnt/volume/jupyter/szokereso/corporate2.csv',\n",
    "                             multisheet=False,\n",
    "                             columnsfiltered=False,\n",
    "                             alias_separator='|'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_sorted_by_date_after_a_date(look_for_this_pattern, cutoffdate):\n",
    "    csvs = glob.glob(look_for_this_pattern)\n",
    "    datetimes=[datetime.datetime(*[int(num) for num in re.findall(r'\\d+', each)[:4]]) for each in csvs]\n",
    "    dt_csvs_filtered=[[dt, csv] for dt, csv in zip(datetimes,csvs) if dt >= datetime.datetime(*cutoffdate)]\n",
    "    sorted_filtered_csvs = [csv\n",
    "                        for _, csv in sorted(\n",
    "                                         zip([eachpair[0] for eachpair in dt_csvs_filtered],\n",
    "                                             [eachpair[1] for eachpair in dt_csvs_filtered]))]\n",
    "    return sorted_filtered_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.dictionary_class object at 0x7fedad401eb8>\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n"
     ]
    }
   ],
   "source": [
    "debugmode = False\n",
    "inputPathAndWildcard = '/mnt/volume/anagy/mediascraper/mediaScraper/output/data*csv'\n",
    "todoFiles=get_files_sorted_by_date_after_a_date(inputPathAndWildcard,[2020,7,1,0])\n",
    "while True:\n",
    "    targetcsv=todoFiles[0]\n",
    "    \n",
    "    targetdf = pd.read_csv(targetcsv)\n",
    "    \n",
    "    num_of_columns_for_each_dict={dictionary.name: dictionary.maxcolnum for dictionary in dictionaries}\n",
    "    for each in num_of_columns_for_each_dict:\n",
    "        for index in range(num_of_columns_for_each_dict[each]):\n",
    "            targetdf[each + str(index)]=''\n",
    "   \n",
    "    cells = list(targetdf['TEXT'])\n",
    "    \n",
    "    for idictionary, dictionary in enumerate(dictionaries):\n",
    "        print(dictionary)\n",
    "        for icell, cell in enumerate(list(targetdf['TEXT'])):\n",
    "            if icell%100 == 0: print(icell)\n",
    "            if type(cell) is not float\\\n",
    "            and not len(matchfinder(cell,dictionary.searchlist)) > dictionary.maxcolnum\\\n",
    "            and len(matchfinder(cell,dictionary.searchlist))>0:\n",
    "                for i, e in enumerate(matchfinder(cell,dictionary.searchlist)):\n",
    "                    targetdf.loc[icell,dictionary.name+str(i)]=e  \n",
    "    \n",
    "    targetdf.to_csv('resultfiles/nagyszokereso_'+targetcsv.split('/')[-1])\n",
    "    \n",
    "    todofiles=get_files_sorted_by_date_after_a_date('/mnt/volume/anagy/mediascraper/mediaScraper/output/data*csv',\n",
    "                filetime(todofiles[0])[:3]+[filetime(todofiles[0])[-1]+1]) # hour increased by 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
